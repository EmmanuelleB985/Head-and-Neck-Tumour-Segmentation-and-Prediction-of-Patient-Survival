{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Survival_HK.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZRqBa509goa",
        "outputId": "f99293df-7a9e-4152-e72e-35142b02a2e5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VueXUFEr9j3_",
        "outputId": "f7445a6c-31ab-47dc-d002-93283ba3e178"
      },
      "source": [
        "cd /content/gdrive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDEf9naxTrsb"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acPP0vfrFDaC"
      },
      "source": [
        "# **1. Data Pre-Processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbGRUsmS98Y9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso, LogisticRegression\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnpj9Dqh9hNH",
        "outputId": "53793a3a-888b-46d4-9990-984dd59556c0"
      },
      "source": [
        "# Load training data \n",
        "endpoint_data =  pd.read_csv(\"hecktor2021_patient_endpoint_training.csv\")\n",
        "endpoint_data = endpoint_data.drop(labels=206, axis=0) # missing ct image\n",
        "print(endpoint_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    PatientID  Progression  Progression free survival\n",
            "0     CHGJ007            1                        310\n",
            "1     CHGJ008            0                       2037\n",
            "2     CHGJ010            0                       1917\n",
            "3     CHGJ013            0                       1377\n",
            "4     CHGJ015            0                       1072\n",
            "..        ...          ...                        ...\n",
            "219   CHUP019            1                        161\n",
            "220   CHUP020            1                        394\n",
            "221   CHUP021            0                        874\n",
            "222   CHUP022            0                       2401\n",
            "223   CHUP023            1                        402\n",
            "\n",
            "[223 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az0AYht79uQV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcab1013-58f4-4a78-fb78-9e5ed98ddab6"
      },
      "source": [
        "# Read the clinical dataset \n",
        "info_data = pd.read_csv(\"hecktor2021_patient_info_training.csv\")\n",
        "clinical = info_data.sort_values(by = 'PatientID')\n",
        "clinical = clinical.drop(labels=206, axis=0)  \n",
        "clinical=clinical.drop(columns=['Estimated weight (kg) for SUV','CenterID'])\n",
        "clinical = clinical.rename({'T-stage': 'Tstage', 'N-stage': 'Nstage', 'M-stage': 'Mstage', 'TNM group':'TNMgroup'}, axis='columns')\n",
        "\n",
        "# Reset the index in ascending order\n",
        "clinical = clinical.reset_index(drop=True)\n",
        "clinical.to_csv('/content/gdrive/My Drive/clinical.csv')\n",
        "print (clinical)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    PatientID  Gender (1=M,0=F)  ...  HPV status (0=-, 1=+)  Chemotherapy\n",
            "0     CHGJ007                 1  ...                    1.0             1\n",
            "1     CHGJ008                 1  ...                    NaN             1\n",
            "2     CHGJ010                 0  ...                    0.0             1\n",
            "3     CHGJ013                 0  ...                    1.0             1\n",
            "4     CHGJ015                 0  ...                    NaN             1\n",
            "..        ...               ...  ...                    ...           ...\n",
            "218   CHUS096                 1  ...                    1.0             0\n",
            "219   CHUS097                 1  ...                    1.0             1\n",
            "220   CHUS098                 1  ...                    1.0             1\n",
            "221   CHUS100                 1  ...                    1.0             1\n",
            "222   CHUS101                 1  ...                    0.0             1\n",
            "\n",
            "[223 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKxodms27gQI",
        "outputId": "d3ec66cf-6360-404a-8f52-b78022e938b1"
      },
      "source": [
        "# Read the clinical test dataset \n",
        "test_data = pd.read_csv(\"hecktor2021_patient_info_testing.csv\")\n",
        "test = test_data.sort_values(by = 'PatientID_hecktor')\n",
        "test = test.drop(columns=['Estimated weight (kg) for SUV','CenterID'])\n",
        "test = test.rename({'T-stage': 'Tstage', 'N-stage': 'Nstage', 'M-stage': 'Mstage', 'TNM group':'TNMgroup'}, axis='columns')\n",
        "\n",
        "# Reset the index in ascending order\n",
        "test = test.reset_index(drop=True)\n",
        "test.to_csv('/content/gdrive/My Drive/test.csv')\n",
        "print (test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    PatientID_hecktor  Gender (1=M,0=F)  ...  HPV status (0=-, 1=+)  Chemotherapy\n",
            "0             CHUP025                 1  ...                    0.0             1\n",
            "1             CHUP026                 1  ...                    0.0             1\n",
            "2             CHUP027                 1  ...                    0.0             1\n",
            "3             CHUP028                 1  ...                    NaN             1\n",
            "4             CHUP029                 0  ...                    0.0             1\n",
            "..                ...               ...  ...                    ...           ...\n",
            "96            CHUV049                 1  ...                    NaN             1\n",
            "97            CHUV050                 0  ...                    NaN             1\n",
            "98            CHUV051                 1  ...                    NaN             1\n",
            "99            CHUV052                 0  ...                    NaN             1\n",
            "100           CHUV053                 1  ...                    NaN             1\n",
            "\n",
            "[101 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFHH7p_nADXf"
      },
      "source": [
        "test['PatientID'] = test['PatientID_hecktor'] #rename column for correspondence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab-bW_5hAVsd"
      },
      "source": [
        "test = test.drop(columns=['Performance status_2.0'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvm6pSlwtcL4"
      },
      "source": [
        "Create dummy variables for the categorical data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaS1lXiDejgT"
      },
      "source": [
        "\n",
        "clinical['Tstage']=clinical.Tstage.apply(lambda x: 0 if x=='T1' \n",
        "                                                      else 1 if x=='T2' \n",
        "                                                      else 2 if x=='T3' \n",
        "                                                      else 3)\n",
        "\n",
        "clinical['Nstage']=clinical.Nstage.apply(lambda x: 0 if x == 'N0' \n",
        "                                                      else 1 if x=='N1' \n",
        "                                                      else 2 if x in('N2', 'N2a','N2b','N2c') \n",
        "                                                      else 3)\n",
        "\n",
        "clinical['Mstage']=clinical.Nstage.apply(lambda x: 0 if x == 'M0' \n",
        "                                                      else 1)\n",
        "clinical['TNMgroup']=clinical.TNMgroup.apply(lambda x: 0 if x == 'I' \n",
        "                                                      else 1 if x=='II' \n",
        "                                                      else 2 if x=='III' \n",
        "                                                      else 3) \n",
        "\n",
        "categories = ['Tstage','Nstage','Mstage','TNMgroup','Tobacco','Alcohol','Gender (1=M,0=F)','Performance status','TNM edition','HPV status (0=-, 1=+)']\n",
        "clinical = pd.get_dummies(clinical, columns=categories, drop_first=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEK0W6E5t5-K"
      },
      "source": [
        "Repeat process for test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0dKZ6CvAnwC"
      },
      "source": [
        "\n",
        "test['Tstage']=test.Tstage.apply(lambda x: 0 if x=='T1' \n",
        "                                                      else 1 if x=='T2' \n",
        "                                                      else 2 if x=='T3' \n",
        "                                                      else 3)\n",
        "\n",
        "test['Nstage']=test.Nstage.apply(lambda x: 0 if x == 'N0' \n",
        "                                                      else 1 if x=='N1' \n",
        "                                                      else 2 if x in('N2', 'N2a','N2b','N2c') \n",
        "                                                      else 3)\n",
        "\n",
        "test['Mstage']=test.Nstage.apply(lambda x: 0 if x == 'M0' \n",
        "                                                      else 1)\n",
        "test['TNMgroup']=test.TNMgroup.apply(lambda x: 0 if x == 'I' \n",
        "                                                      else 1 if x=='II' \n",
        "                                                      else 2 if x=='III' \n",
        "                                                      else 3) \n",
        "\n",
        "categories = ['Tstage','Nstage','Mstage','TNMgroup','Tobacco','Alcohol','Gender (1=M,0=F)','Performance status','TNM edition','HPV status (0=-, 1=+)']\n",
        "test = pd.get_dummies(test, columns=categories, drop_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mbw0UC4InGl"
      },
      "source": [
        "Read extracted pet features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUiAivLq-ESL",
        "outputId": "f99948c3-5e0c-4483-b94d-898df8518f47"
      },
      "source": [
        "\n",
        "def extract_pet_features(path_pet_features):\n",
        "    pet_features = pd.read_csv(path_pet_features)\n",
        "    # Sort the rows of dataframe by 'Name' column\n",
        "    pet_features = pet_features.sort_values(by = 'patients_id')\n",
        "    # Reset the index in ascending order\n",
        "    pet_features = pet_features.reset_index(drop=True)\n",
        "    return pet_features\n",
        "\n",
        "pet_features = extract_pet_features(\"extracted_features_pet.csv\")\n",
        "pet_features_test = extract_pet_features(\"extracted_features_pet_test.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    patients_id  ... original_ngtdm_Strength\n",
            "0       CHGJ007  ...                     1.0\n",
            "1       CHGJ008  ...                     0.0\n",
            "2       CHGJ010  ...                     0.0\n",
            "3       CHGJ013  ...                     0.0\n",
            "4       CHGJ015  ...                     0.0\n",
            "..          ...  ...                     ...\n",
            "218     CHUS096  ...                     0.0\n",
            "219     CHUS097  ...                     0.0\n",
            "220     CHUS098  ...                     0.0\n",
            "221     CHUS100  ...                     0.0\n",
            "222     CHUS101  ...                     0.0\n",
            "\n",
            "[223 rows x 130 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG9OVD3hIsoH"
      },
      "source": [
        "Read extracted ct features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bg_z0pe9wIJ",
        "outputId": "05a2f49f-cf2c-40a2-9e24-aa9d7bcbca34"
      },
      "source": [
        "\n",
        "def extract_ct_features(path_ct_features):\n",
        "    ct_features = pd.read_csv(path_ct_features)\n",
        "    # Sort the rows of dataframe by 'Name' column\n",
        "    ct_features = ct_features.sort_values(by = 'patients_id')\n",
        "    # Reset the index in ascending order\n",
        "    ct_features = ct_features.reset_index(drop=True)\n",
        "    return ct_features\n",
        "\n",
        "ct_features = extract_pet_features(\"extracted_features_ct.csv\")\n",
        "test_ct_features = extract_pet_features(\"extracted_features_ct_test.csv\")\n",
        "print (ct_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    patients_id  ... original_ngtdm_Strength\n",
            "0       CHGJ007  ...                     1.0\n",
            "1       CHGJ008  ...                     0.0\n",
            "2       CHGJ010  ...                     0.0\n",
            "3       CHGJ013  ...                     0.0\n",
            "4       CHGJ015  ...                     0.0\n",
            "..          ...  ...                     ...\n",
            "218     CHUS096  ...                     0.0\n",
            "219     CHUS097  ...                     0.0\n",
            "220     CHUS098  ...                     0.0\n",
            "221     CHUS100  ...                     0.0\n",
            "222     CHUS101  ...                     0.0\n",
            "\n",
            "[223 rows x 130 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A78D3--HI21i"
      },
      "source": [
        "Read extracted deep features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7KwRJ9qao5Q"
      },
      "source": [
        "\n",
        "def extract_deep_features(path_deep_features):\n",
        "    deep_features = pd.read_csv(path_deep_features)\n",
        "    deep_features = deep_features.rename(columns={'Unnamed: 0': 'PatientID'})\n",
        "    # Sort the rows of dataframe by 'Name' column\n",
        "    deep_features = deep_features.sort_values(by = 'PatientID')\n",
        "    # Reset the index in ascending order\n",
        "    deep_features = deep_features.reset_index(drop=True)\n",
        "    return deep_features\n",
        "\n",
        "deep_features = extract_deep_features(\"features_unet.csv\")\n",
        "test_deep_features = extract_deep_features(\"features_unet_test.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjYssnFcERbD",
        "outputId": "10901db1-41bc-4c6f-cbc5-9cfa7952caf1"
      },
      "source": [
        "print(test_deep_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    PatientID          0          1  ...        141        142        143\n",
            "0     CHUP040   1.561144   2.663644  ...  10.427158   5.928310  -0.931872\n",
            "1     CHUP060   3.707203   6.315398  ...  14.774714  15.243038  10.462632\n",
            "2     CHUV025   0.246460   1.112381  ...  12.781462   6.786904  -0.822516\n",
            "3     CHUP034   6.571823   9.034449  ...  20.070354  21.655520  15.204715\n",
            "4     CHUP054  -0.531894  -0.320032  ...  36.351437  22.548420   4.281902\n",
            "..        ...        ...        ...  ...        ...        ...        ...\n",
            "96    CHUP061  23.884945  32.692055  ...   9.529576   5.397012  -1.686181\n",
            "97    CHUV010   1.771936   2.714971  ...  40.131660  22.852820   4.033140\n",
            "98    CHUP055   0.946515   1.620571  ...  25.121386  26.151447  20.205112\n",
            "99    CHUP049  13.689615  18.164381  ...  28.405163  17.439287   2.066371\n",
            "100   CHUV006   3.084119   4.423283  ...  26.422005  16.003588   1.538562\n",
            "\n",
            "[101 rows x 145 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvmMOMHQE7kz"
      },
      "source": [
        "# Multiple imputation for missing values (clinical data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vMZXngrzeLs"
      },
      "source": [
        "#Select numerical columns \n",
        "numeric_cols = clinical.drop(columns=['PatientID']).select_dtypes(exclude='number')\n",
        "clinical.drop(numeric_cols, axis=1, inplace=True)\n",
        "numeric_cols = test.drop(columns=['PatientID']).select_dtypes(exclude='number')\n",
        "test.drop(numeric_cols, axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mGct8_LoK4n",
        "outputId": "d4fb4201-3ff7-48a9-80ee-beb95c78248b"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()\n",
        "imp = IterativeImputer(estimator=lr,missing_values=np.nan, max_iter=10, verbose=2, imputation_order='roman',random_state=0)\n",
        "\n",
        "clinical_imputed=imp.fit_transform(clinical.drop(columns=['PatientID']))\n",
        "clinical_imputed = pd.DataFrame(clinical_imputed, columns = test.drop(columns=['PatientID']).columns)\n",
        "test_imputed=imp.fit_transform(test.drop(columns=['PatientID']))\n",
        "test_imputed = pd.DataFrame(test_imputed, columns = test.drop(columns=['PatientID']).columns)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IterativeImputer] Completing matrix with shape (101, 17)\n",
            "[IterativeImputer] Ending imputation round 1/10, elapsed time 0.02\n",
            "[IterativeImputer] Change: 0.0, scaled tolerance: 0.084 \n",
            "[IterativeImputer] Early stopping criterion reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVWFQt_7EwpZ"
      },
      "source": [
        "# Data Merging and Train-Test Split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXZFmpRfyujp"
      },
      "source": [
        "# Several models were tested with a combination of clinical, ct, pet and deep features. \n",
        "# Best results obtained with a mixture of clinical, ct and deep features.\n",
        "\n",
        "data = pd.concat([clinical_imputed, ct_features], axis=1, join='inner',ignore_index=False, sort=False)\n",
        "data = pd.concat([data, ct_features], axis=1, join='inner',ignore_index=False, sort=False)\n",
        "\n",
        "data_test = pd.concat([test_imputed, deep_features],axis=1,join='inner',ignore_index=False, sort=False)\n",
        "data_test = pd.concat([data_test, test_ct_features],axis=1,join='inner',ignore_index=False, sort=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-fbBZUmEvP6",
        "outputId": "81341e24-6a89-43d3-c0d6-d01660de374f"
      },
      "source": [
        "# Separate into training and test set for model training \n",
        "X_train, X_val, y_train, y_val = train_test_split(data,\n",
        "    endpoint_data['Progression free survival'],\n",
        "    test_size=0.3,\n",
        "    random_state=0) \n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((156, 274), (67, 274))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1WknyrWEhHT"
      },
      "source": [
        "# Features Selection using Lasso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvLkAaUUWsAn"
      },
      "source": [
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import Lasso, LogisticRegression\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMOl8c6TW8ae"
      },
      "source": [
        "# Lasso regression with 5-fold cross-validation \n",
        "pipeline = Pipeline([\n",
        "                     ('scaler',StandardScaler()),\n",
        "                     ('model',Lasso())\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tEn3oVDW-Qb"
      },
      "source": [
        "\n",
        "search = GridSearchCV(pipeline,\n",
        "                      {'model__alpha':np.arange(0.1,10,0.1)},\n",
        "                      cv = 5, scoring=\"neg_mean_squared_error\",verbose=3\n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2EbHfIZXBir",
        "outputId": "074fde68-c33a-46d4-d674-b943010348b8"
      },
      "source": [
        "search.fit(X_train.drop(columns=['PatientID']),y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 99 candidates, totalling 495 fits\n",
            "[CV] model__alpha=0.1 ................................................\n",
            "[CV] ............. model__alpha=0.1, score=-2156395.654, total=   0.1s\n",
            "[CV] model__alpha=0.1 ................................................\n",
            "[CV] ............. model__alpha=0.1, score=-2082862.270, total=   0.1s\n",
            "[CV] model__alpha=0.1 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 201042.2283021267, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 226098.1583161126, tolerance: 4494.4464272\n",
            "  positive)\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 186306.61835188628, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 201672.30441301348, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 137251.50549129347, tolerance: 4269.2907392\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=0.1, score=-1864616.813, total=   0.1s\n",
            "[CV] model__alpha=0.1 ................................................\n",
            "[CV] ............. model__alpha=0.1, score=-2313447.520, total=   0.1s\n",
            "[CV] model__alpha=0.1 ................................................\n",
            "[CV] ............. model__alpha=0.1, score=-1086335.249, total=   0.1s\n",
            "[CV] model__alpha=0.2 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 260917.27798686028, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 299521.42307358637, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 303629.0674963844, tolerance: 4545.2030112\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=0.2, score=-1911140.795, total=   0.1s\n",
            "[CV] model__alpha=0.2 ................................................\n",
            "[CV] ............. model__alpha=0.2, score=-1999924.606, total=   0.1s\n",
            "[CV] model__alpha=0.2 ................................................\n",
            "[CV] ............. model__alpha=0.2, score=-2090053.844, total=   0.1s\n",
            "[CV] model__alpha=0.2 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 357524.27323701326, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 286194.4824812032, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 263020.02520375734, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=0.2, score=-2252088.935, total=   0.1s\n",
            "[CV] model__alpha=0.2 ................................................\n",
            "[CV] ............. model__alpha=0.2, score=-1033028.818, total=   0.1s\n",
            "[CV] model__alpha=0.30000000000000004 ................................\n",
            "[CV]  model__alpha=0.30000000000000004, score=-1648076.775, total=   0.1s\n",
            "[CV] model__alpha=0.30000000000000004 ................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 366551.1796285652, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 311750.2904430999, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 302538.57380262966, tolerance: 4930.625720000001\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=0.30000000000000004, score=-1887402.650, total=   0.1s\n",
            "[CV] model__alpha=0.30000000000000004 ................................\n",
            "[CV]  model__alpha=0.30000000000000004, score=-2196746.241, total=   0.1s\n",
            "[CV] model__alpha=0.30000000000000004 ................................\n",
            "[CV]  model__alpha=0.30000000000000004, score=-2193159.401, total=   0.1s\n",
            "[CV] model__alpha=0.30000000000000004 ................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 383871.33509416314, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196827.84974216914, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 368295.41722774616, tolerance: 4494.4464272\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=0.30000000000000004, score=-1019066.326, total=   0.1s\n",
            "[CV] model__alpha=0.4 ................................................\n",
            "[CV] ............. model__alpha=0.4, score=-1551867.439, total=   0.1s\n",
            "[CV] model__alpha=0.4 ................................................\n",
            "[CV] ............. model__alpha=0.4, score=-1800458.036, total=   0.1s\n",
            "[CV] model__alpha=0.4 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 268590.1386394501, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 416421.1731450056, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 395632.46908487886, tolerance: 4269.2907392\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=0.4, score=-2236126.210, total=   0.1s\n",
            "[CV] model__alpha=0.4 ................................................\n",
            "[CV] ............. model__alpha=0.4, score=-2071473.051, total=   0.1s\n",
            "[CV] model__alpha=0.4 ................................................\n",
            "[CV] .............. model__alpha=0.4, score=-978423.104, total=   0.1s\n",
            "[CV] model__alpha=0.5 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 267456.87399684824, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 535479.5592029078, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 306975.1612265267, tolerance: 4545.2030112\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=0.5, score=-1532323.603, total=   0.1s\n",
            "[CV] model__alpha=0.5 ................................................\n",
            "[CV] ............. model__alpha=0.5, score=-1737728.666, total=   0.1s\n",
            "[CV] model__alpha=0.5 ................................................\n",
            "[CV] ............. model__alpha=0.5, score=-2185563.040, total=   0.1s\n",
            "[CV] model__alpha=0.5 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 582465.9480327044, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 330265.8066317923, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 310507.9285904238, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=0.5, score=-1972532.713, total=   0.1s\n",
            "[CV] model__alpha=0.5 ................................................\n",
            "[CV] .............. model__alpha=0.5, score=-944281.429, total=   0.1s\n",
            "[CV] model__alpha=0.6 ................................................\n",
            "[CV] ............. model__alpha=0.6, score=-1441678.618, total=   0.1s\n",
            "[CV] model__alpha=0.6 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 668728.7617542257, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 323831.06734942994, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 519155.37144869403, tolerance: 4930.625720000001\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=0.6, score=-1673903.147, total=   0.1s\n",
            "[CV] model__alpha=0.6 ................................................\n",
            "[CV] ............. model__alpha=0.6, score=-2122847.292, total=   0.1s\n",
            "[CV] model__alpha=0.6 ................................................\n",
            "[CV] ............. model__alpha=0.6, score=-1843053.723, total=   0.1s\n",
            "[CV] model__alpha=0.6 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 278403.8874638146, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 294203.52253975795, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 615001.6786087767, tolerance: 4494.4464272\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=0.6, score=-948968.772, total=   0.1s\n",
            "[CV] model__alpha=0.7000000000000001 .................................\n",
            "[CV]  model__alpha=0.7000000000000001, score=-1351030.138, total=   0.1s\n",
            "[CV] model__alpha=0.7000000000000001 .................................\n",
            "[CV]  model__alpha=0.7000000000000001, score=-1648925.863, total=   0.1s\n",
            "[CV] model__alpha=0.7000000000000001 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 275254.1695169954, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 333395.2076474763, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 178773.34817370458, tolerance: 4269.2907392\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=0.7000000000000001, score=-2054675.173, total=   0.1s\n",
            "[CV] model__alpha=0.7000000000000001 .................................\n",
            "[CV]  model__alpha=0.7000000000000001, score=-1725209.524, total=   0.1s\n",
            "[CV] model__alpha=0.7000000000000001 .................................\n",
            "[CV]  model__alpha=0.7000000000000001, score=-943566.106, total=   0.1s\n",
            "[CV] model__alpha=0.8 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196177.7730167855, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 591911.3584137438, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 241955.3970766241, tolerance: 4545.2030112\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=0.8, score=-1262858.098, total=   0.1s\n",
            "[CV] model__alpha=0.8 ................................................\n",
            "[CV] ............. model__alpha=0.8, score=-1652710.210, total=   0.1s\n",
            "[CV] model__alpha=0.8 ................................................\n",
            "[CV] ............. model__alpha=0.8, score=-1970604.655, total=   0.1s\n",
            "[CV] model__alpha=0.8 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 470758.4233836379, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 167200.84729428403, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 182023.3181027989, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=0.8, score=-1647663.777, total=   0.1s\n",
            "[CV] model__alpha=0.8 ................................................\n",
            "[CV] .............. model__alpha=0.8, score=-947283.376, total=   0.1s\n",
            "[CV] model__alpha=0.9 ................................................\n",
            "[CV] ............. model__alpha=0.9, score=-1174680.520, total=   0.1s\n",
            "[CV] model__alpha=0.9 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 654078.7306808069, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 207531.93906937033, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 546544.1306186855, tolerance: 4930.625720000001\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=0.9, score=-1679153.177, total=   0.1s\n",
            "[CV] model__alpha=0.9 ................................................\n",
            "[CV] ............. model__alpha=0.9, score=-1874604.304, total=   0.1s\n",
            "[CV] model__alpha=0.9 ................................................\n",
            "[CV] ............. model__alpha=0.9, score=-1581471.164, total=   0.1s\n",
            "[CV] model__alpha=0.9 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 156876.83638037485, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 180748.3678482289, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 274614.6821022853, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 232178.19645289378, tolerance: 4545.2030112\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=0.9, score=-954653.340, total=   0.1s\n",
            "[CV] model__alpha=1.0 ................................................\n",
            "[CV] ............. model__alpha=1.0, score=-1104068.055, total=   0.1s\n",
            "[CV] model__alpha=1.0 ................................................\n",
            "[CV] ............. model__alpha=1.0, score=-1712765.962, total=   0.1s\n",
            "[CV] model__alpha=1.0 ................................................\n",
            "[CV] ............. model__alpha=1.0, score=-1782657.765, total=   0.1s\n",
            "[CV] model__alpha=1.0 ................................................\n",
            "[CV] ............. model__alpha=1.0, score=-1511815.455, total=   0.1s\n",
            "[CV] model__alpha=1.0 ................................................\n",
            "[CV] .............. model__alpha=1.0, score=-974655.189, total=   0.1s\n",
            "[CV] model__alpha=1.1 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 616348.4733829282, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 105368.55218593823, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 226445.1710465037, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=1.1, score=-1050084.663, total=   0.1s\n",
            "[CV] model__alpha=1.1 ................................................\n",
            "[CV] ............. model__alpha=1.1, score=-1747447.490, total=   0.1s\n",
            "[CV] model__alpha=1.1 ................................................\n",
            "[CV] ............. model__alpha=1.1, score=-1694544.206, total=   0.1s\n",
            "[CV] model__alpha=1.1 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 242726.3388896149, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 229868.40320479497, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 622369.32657653, tolerance: 4930.625720000001\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=1.1, score=-1470095.467, total=   0.1s\n",
            "[CV] model__alpha=1.1 ................................................\n",
            "[CV] .............. model__alpha=1.1, score=-984893.538, total=   0.1s\n",
            "[CV] model__alpha=1.2000000000000002 .................................\n",
            "[CV]  model__alpha=1.2000000000000002, score=-1019749.328, total=   0.1s\n",
            "[CV] model__alpha=1.2000000000000002 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 90859.73361631215, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 133435.21168538858, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 220568.62696801685, tolerance: 4494.4464272\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=1.2000000000000002, score=-1757559.358, total=   0.1s\n",
            "[CV] model__alpha=1.2000000000000002 .................................\n",
            "[CV]  model__alpha=1.2000000000000002, score=-1627032.094, total=   0.1s\n",
            "[CV] model__alpha=1.2000000000000002 .................................\n",
            "[CV]  model__alpha=1.2000000000000002, score=-1424899.713, total=   0.1s\n",
            "[CV] model__alpha=1.2000000000000002 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198177.23904479074, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 611543.2537915421, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 84008.6606461429, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 102043.73772264807, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=1.2000000000000002, score=-992399.195, total=   0.1s\n",
            "[CV] model__alpha=1.3000000000000003 .................................\n",
            "[CV]  model__alpha=1.3000000000000003, score=-996613.236, total=   0.1s\n",
            "[CV] model__alpha=1.3000000000000003 .................................\n",
            "[CV]  model__alpha=1.3000000000000003, score=-1754199.097, total=   0.1s\n",
            "[CV] model__alpha=1.3000000000000003 .................................\n",
            "[CV]  model__alpha=1.3000000000000003, score=-1595696.245, total=   0.1s\n",
            "[CV] model__alpha=1.3000000000000003 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 175884.69146656664, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 144015.01217363472, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 584901.9553536575, tolerance: 4930.625720000001\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=1.3000000000000003, score=-1377185.580, total=   0.1s\n",
            "[CV] model__alpha=1.3000000000000003 .................................\n",
            "[CV]  model__alpha=1.3000000000000003, score=-1005091.371, total=   0.1s\n",
            "[CV] model__alpha=1.4000000000000001 .................................\n",
            "[CV]  model__alpha=1.4000000000000001, score=-976070.240, total=   0.1s\n",
            "[CV] model__alpha=1.4000000000000001 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 76666.65135571081, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 98107.7099647324, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 137529.07735410938, tolerance: 4494.4464272\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=1.4000000000000001, score=-1735407.846, total=   0.1s\n",
            "[CV] model__alpha=1.4000000000000001 .................................\n",
            "[CV]  model__alpha=1.4000000000000001, score=-1564177.422, total=   0.1s\n",
            "[CV] model__alpha=1.4000000000000001 .................................\n",
            "[CV]  model__alpha=1.4000000000000001, score=-1334855.985, total=   0.1s\n",
            "[CV] model__alpha=1.4000000000000001 .................................\n",
            "[CV]  model__alpha=1.4000000000000001, score=-1005044.436, total=   0.1s\n",
            "[CV] model__alpha=1.5000000000000002 ................................."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 139471.6042656526, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 575030.6050039921, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 84533.66374175856, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 77218.90229638969, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[CV]  model__alpha=1.5000000000000002, score=-961940.373, total=   0.1s\n",
            "[CV] model__alpha=1.5000000000000002 .................................\n",
            "[CV]  model__alpha=1.5000000000000002, score=-1710478.922, total=   0.1s\n",
            "[CV] model__alpha=1.5000000000000002 .................................\n",
            "[CV]  model__alpha=1.5000000000000002, score=-1517355.596, total=   0.1s\n",
            "[CV] model__alpha=1.5000000000000002 ................................."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 122722.3065123572, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95032.34692543698, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 513352.3948870925, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47902.368504586164, tolerance: 4269.2907392\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[CV]  model__alpha=1.5000000000000002, score=-1295114.629, total=   0.1s\n",
            "[CV] model__alpha=1.5000000000000002 .................................\n",
            "[CV]  model__alpha=1.5000000000000002, score=-995266.878, total=   0.1s\n",
            "[CV] model__alpha=1.6 ................................................\n",
            "[CV] .............. model__alpha=1.6, score=-941690.543, total=   0.1s\n",
            "[CV] model__alpha=1.6 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 80418.91276068008, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 118383.85682382039, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 94631.16483609541, tolerance: 4545.2030112\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=1.6, score=-1678900.785, total=   0.1s\n",
            "[CV] model__alpha=1.6 ................................................\n",
            "[CV] ............. model__alpha=1.6, score=-1472719.173, total=   0.1s\n",
            "[CV] model__alpha=1.6 ................................................\n",
            "[CV] ............. model__alpha=1.6, score=-1248357.543, total=   0.1s\n",
            "[CV] model__alpha=1.6 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 358793.21805138374, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 55850.09555229684, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 83648.4168152716, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=1.6, score=-987476.438, total=   0.1s\n",
            "[CV] model__alpha=1.7000000000000002 .................................\n",
            "[CV]  model__alpha=1.7000000000000002, score=-1076925.217, total=   0.1s\n",
            "[CV] model__alpha=1.7000000000000002 .................................\n",
            "[CV]  model__alpha=1.7000000000000002, score=-1650574.018, total=   0.1s\n",
            "[CV] model__alpha=1.7000000000000002 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96267.90341368597, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 82039.29183077766, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 249802.84927176242, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56628.05317861773, tolerance: 4269.2907392\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=1.7000000000000002, score=-1429271.464, total=   0.1s\n",
            "[CV] model__alpha=1.7000000000000002 .................................\n",
            "[CV]  model__alpha=1.7000000000000002, score=-1211279.733, total=   0.1s\n",
            "[CV] model__alpha=1.7000000000000002 .................................\n",
            "[CV]  model__alpha=1.7000000000000002, score=-980801.541, total=   0.1s\n",
            "[CV] model__alpha=1.8000000000000003 .................................\n",
            "[CV]  model__alpha=1.8000000000000003, score=-1325131.592, total=   0.1s\n",
            "[CV] model__alpha=1.8000000000000003 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 57285.707520481665, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 102706.27986403368, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 77852.20070231217, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 213022.566254294, tolerance: 4930.625720000001\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=1.8000000000000003, score=-1622104.636, total=   0.1s\n",
            "[CV] model__alpha=1.8000000000000003 .................................\n",
            "[CV]  model__alpha=1.8000000000000003, score=-1390079.785, total=   0.1s\n",
            "[CV] model__alpha=1.8000000000000003 .................................\n",
            "[CV]  model__alpha=1.8000000000000003, score=-1183728.497, total=   0.1s\n",
            "[CV] model__alpha=1.8000000000000003 .................................\n",
            "[CV]  model__alpha=1.8000000000000003, score=-975831.266, total=   0.1s\n",
            "[CV] model__alpha=1.9000000000000001 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54673.62232789351, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37613.96367826406, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 106134.11661584768, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 79520.40881998953, tolerance: 4545.2030112\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=1.9000000000000001, score=-1546452.448, total=   0.1s\n",
            "[CV] model__alpha=1.9000000000000001 .................................\n",
            "[CV]  model__alpha=1.9000000000000001, score=-1597292.368, total=   0.1s\n",
            "[CV] model__alpha=1.9000000000000001 .................................\n",
            "[CV]  model__alpha=1.9000000000000001, score=-1357644.430, total=   0.1s\n",
            "[CV] model__alpha=1.9000000000000001 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 215256.5683894693, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53066.27171197068, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27727.04501916375, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 103660.94179993868, tolerance: 4494.4464272\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=1.9000000000000001, score=-1169926.150, total=   0.1s\n",
            "[CV] model__alpha=1.9000000000000001 .................................\n",
            "[CV]  model__alpha=1.9000000000000001, score=-965873.971, total=   0.1s\n",
            "[CV] model__alpha=2.0 ................................................\n",
            "[CV] ............. model__alpha=2.0, score=-1704635.876, total=   0.1s\n",
            "[CV] model__alpha=2.0 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 75545.87515511364, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 194796.63259338727, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48920.43118846929, tolerance: 4269.2907392\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=2.0, score=-1570095.744, total=   0.1s\n",
            "[CV] model__alpha=2.0 ................................................\n",
            "[CV] ............. model__alpha=2.0, score=-1328513.746, total=   0.1s\n",
            "[CV] model__alpha=2.0 ................................................\n",
            "[CV] ............. model__alpha=2.0, score=-1154502.612, total=   0.1s\n",
            "[CV] model__alpha=2.0 ................................................\n",
            "[CV] .............. model__alpha=2.0, score=-952770.170, total=   0.1s\n",
            "[CV] model__alpha=2.1 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21947.07486257376, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 111107.89342655754, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 83237.3024841426, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 159706.21771234693, tolerance: 4930.625720000001\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=2.1, score=-1894727.684, total=   0.1s\n",
            "[CV] model__alpha=2.1 ................................................\n",
            "[CV] ............. model__alpha=2.1, score=-1540088.464, total=   0.1s\n",
            "[CV] model__alpha=2.1 ................................................\n",
            "[CV] ............. model__alpha=2.1, score=-1300216.540, total=   0.1s\n",
            "[CV] model__alpha=2.1 ................................................\n",
            "[CV] ............. model__alpha=2.1, score=-1128826.607, total=   0.1s\n",
            "[CV] model__alpha=2.1 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36626.93560081208, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17739.975969154388, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 109227.66598487552, tolerance: 4494.4464272\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=2.1, score=-946335.267, total=   0.1s\n",
            "[CV] model__alpha=2.2 ................................................\n",
            "[CV] ............. model__alpha=2.2, score=-2135590.088, total=   0.1s\n",
            "[CV] model__alpha=2.2 ................................................\n",
            "[CV] ............. model__alpha=2.2, score=-1505828.531, total=   0.1s\n",
            "[CV] model__alpha=2.2 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 84987.28228648333, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 137780.54366340302, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26199.117889273446, tolerance: 4269.2907392\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=2.2, score=-1271902.640, total=   0.1s\n",
            "[CV] model__alpha=2.2 ................................................\n",
            "[CV] ............. model__alpha=2.2, score=-1102113.029, total=   0.1s\n",
            "[CV] model__alpha=2.2 ................................................\n",
            "[CV] .............. model__alpha=2.2, score=-942335.602, total=   0.1s\n",
            "[CV] model__alpha=2.3000000000000003 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12830.244126089849, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 99989.12915789429, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 89327.41214035312, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 109284.997428298, tolerance: 4930.625720000001\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=2.3000000000000003, score=-2406355.521, total=   0.1s\n",
            "[CV] model__alpha=2.3000000000000003 .................................\n",
            "[CV]  model__alpha=2.3000000000000003, score=-1464902.758, total=   0.1s\n",
            "[CV] model__alpha=2.3000000000000003 .................................\n",
            "[CV]  model__alpha=2.3000000000000003, score=-1241739.750, total=   0.1s\n",
            "[CV] model__alpha=2.3000000000000003 .................................\n",
            "[CV]  model__alpha=2.3000000000000003, score=-1079659.428, total=   0.1s\n",
            "[CV] model__alpha=2.3000000000000003 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14845.5375979878, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13470.252440999728, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101089.10403702362, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 100923.53927286528, tolerance: 4545.2030112\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=2.3000000000000003, score=-941330.799, total=   0.1s\n",
            "[CV] model__alpha=2.4000000000000004 .................................\n",
            "[CV]  model__alpha=2.4000000000000004, score=-3091018.179, total=   0.1s\n",
            "[CV] model__alpha=2.4000000000000004 .................................\n",
            "[CV]  model__alpha=2.4000000000000004, score=-1425917.238, total=   0.1s\n",
            "[CV] model__alpha=2.4000000000000004 .................................\n",
            "[CV]  model__alpha=2.4000000000000004, score=-1211849.379, total=   0.1s\n",
            "[CV] model__alpha=2.4000000000000004 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 81365.65736196283, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7149.545037634205, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16804.996300997213, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 109547.9200684363, tolerance: 4494.4464272\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=2.4000000000000004, score=-1068791.914, total=   0.1s\n",
            "[CV] model__alpha=2.4000000000000004 .................................\n",
            "[CV]  model__alpha=2.4000000000000004, score=-937144.066, total=   0.1s\n",
            "[CV] model__alpha=2.5000000000000004 .................................\n",
            "[CV]  model__alpha=2.5000000000000004, score=-4142714.352, total=   0.1s\n",
            "[CV] model__alpha=2.5000000000000004 .................................\n",
            "[CV]  model__alpha=2.5000000000000004, score=-1387907.056, total=   0.1s\n",
            "[CV] model__alpha=2.5000000000000004 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20262.053847324103, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 70370.03003157303, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5561.347387214191, tolerance: 4269.2907392\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17143.572497297544, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=2.5000000000000004, score=-1190882.230, total=   0.1s\n",
            "[CV] model__alpha=2.5000000000000004 .................................\n",
            "[CV]  model__alpha=2.5000000000000004, score=-1060526.151, total=   0.1s\n",
            "[CV] model__alpha=2.5000000000000004 .................................\n",
            "[CV]  model__alpha=2.5000000000000004, score=-928007.063, total=   0.1s\n",
            "[CV] model__alpha=2.6 ................................................\n",
            "[CV] ............. model__alpha=2.6, score=-5032953.788, total=   0.1s\n",
            "[CV] model__alpha=2.6 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 123502.90487557836, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8674.561126993038, tolerance: 4545.2030112\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52847.78045572247, tolerance: 4930.625720000001\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=2.6, score=-1348858.928, total=   0.1s\n",
            "[CV] model__alpha=2.6 ................................................\n",
            "[CV] ............. model__alpha=2.6, score=-1170534.071, total=   0.1s\n",
            "[CV] model__alpha=2.6 ................................................\n",
            "[CV] ............. model__alpha=2.6, score=-1059042.764, total=   0.1s\n",
            "[CV] model__alpha=2.6 ................................................\n",
            "[CV] .............. model__alpha=2.6, score=-918121.562, total=   0.1s\n",
            "[CV] model__alpha=2.7 ................................................\n",
            "[CV] ............. model__alpha=2.7, score=-5973459.144, total=   0.1s\n",
            "[CV] model__alpha=2.7 ................................................\n",
            "[CV] ............. model__alpha=2.7, score=-1310195.574, total=   0.1s\n",
            "[CV] model__alpha=2.7 ................................................\n",
            "[CV] ............. model__alpha=2.7, score=-1149262.280, total=   0.1s\n",
            "[CV] model__alpha=2.7 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17965.86219146382, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 137126.94469608134, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40982.8437822219, tolerance: 4930.625720000001\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=2.7, score=-1057059.620, total=   0.1s\n",
            "[CV] model__alpha=2.7 ................................................\n",
            "[CV] .............. model__alpha=2.7, score=-910579.892, total=   0.0s\n",
            "[CV] model__alpha=2.8000000000000003 .................................\n",
            "[CV]  model__alpha=2.8000000000000003, score=-6895066.151, total=   0.1s\n",
            "[CV] model__alpha=2.8000000000000003 .................................\n",
            "[CV]  model__alpha=2.8000000000000003, score=-1273996.106, total=   0.1s\n",
            "[CV] model__alpha=2.8000000000000003 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15720.503644399345, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 145938.62107108813, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39624.14538899902, tolerance: 4930.625720000001\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=2.8000000000000003, score=-1134589.789, total=   0.1s\n",
            "[CV] model__alpha=2.8000000000000003 .................................\n",
            "[CV]  model__alpha=2.8000000000000003, score=-1050066.807, total=   0.1s\n",
            "[CV] model__alpha=2.8000000000000003 .................................\n",
            "[CV]  model__alpha=2.8000000000000003, score=-903700.592, total=   0.0s\n",
            "[CV] model__alpha=2.9000000000000004 .................................\n",
            "[CV]  model__alpha=2.9000000000000004, score=-7709001.129, total=   0.1s\n",
            "[CV] model__alpha=2.9000000000000004 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13390.451839700341, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161126.52782867104, tolerance: 4494.4464272\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=2.9000000000000004, score=-1243003.660, total=   0.1s\n",
            "[CV] model__alpha=2.9000000000000004 .................................\n",
            "[CV]  model__alpha=2.9000000000000004, score=-1119018.954, total=   0.1s\n",
            "[CV] model__alpha=2.9000000000000004 .................................\n",
            "[CV]  model__alpha=2.9000000000000004, score=-1038491.415, total=   0.1s\n",
            "[CV] model__alpha=2.9000000000000004 .................................\n",
            "[CV]  model__alpha=2.9000000000000004, score=-897178.090, total=   0.0s\n",
            "[CV] model__alpha=3.0000000000000004 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35231.676714994945, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13528.267431956716, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191001.53660131432, tolerance: 4494.4464272\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=3.0000000000000004, score=-8672861.306, total=   0.1s\n",
            "[CV] model__alpha=3.0000000000000004 .................................\n",
            "[CV]  model__alpha=3.0000000000000004, score=-1214998.852, total=   0.1s\n",
            "[CV] model__alpha=3.0000000000000004 .................................\n",
            "[CV]  model__alpha=3.0000000000000004, score=-1104035.705, total=   0.0s\n",
            "[CV] model__alpha=3.0000000000000004 .................................\n",
            "[CV]  model__alpha=3.0000000000000004, score=-1020238.868, total=   0.1s\n",
            "[CV] model__alpha=3.0000000000000004 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32141.89780256804, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13170.528063811362, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154249.50909768417, tolerance: 4494.4464272\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=3.0000000000000004, score=-892331.841, total=   0.1s\n",
            "[CV] model__alpha=3.1 ................................................\n",
            "[CV] ............. model__alpha=3.1, score=-9560470.994, total=   0.1s\n",
            "[CV] model__alpha=3.1 ................................................\n",
            "[CV] ............. model__alpha=3.1, score=-1184593.232, total=   0.1s\n",
            "[CV] model__alpha=3.1 ................................................\n",
            "[CV] ............. model__alpha=3.1, score=-1090500.864, total=   0.0s\n",
            "[CV] model__alpha=3.1 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25626.45175893046, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15233.453527774662, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 119635.44274824206, tolerance: 4494.4464272\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............. model__alpha=3.1, score=-1002592.926, total=   0.1s\n",
            "[CV] model__alpha=3.1 ................................................\n",
            "[CV] .............. model__alpha=3.1, score=-888692.852, total=   0.0s\n",
            "[CV] model__alpha=3.2 ................................................\n",
            "[CV] ............ model__alpha=3.2, score=-10417797.930, total=   0.1s\n",
            "[CV] model__alpha=3.2 ................................................\n",
            "[CV] ............. model__alpha=3.2, score=-1154002.865, total=   0.1s\n",
            "[CV] model__alpha=3.2 ................................................\n",
            "[CV] ............. model__alpha=3.2, score=-1077202.393, total=   0.1s\n",
            "[CV] model__alpha=3.2 ................................................\n",
            "[CV] .............. model__alpha=3.2, score=-986430.646, total=   0.1s\n",
            "[CV] model__alpha=3.2 ................................................\n",
            "[CV] .............. model__alpha=3.2, score=-885031.413, total=   0.1s\n",
            "[CV] model__alpha=3.3000000000000003 .................................\n",
            "[CV]  model__alpha=3.3000000000000003, score=-11031164.231, total=   0.1s\n",
            "[CV] model__alpha=3.3000000000000003 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11775.772694767453, tolerance: 4930.625720000001\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17216.886427710764, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=3.3000000000000003, score=-1123567.610, total=   0.1s\n",
            "[CV] model__alpha=3.3000000000000003 .................................\n",
            "[CV]  model__alpha=3.3000000000000003, score=-1064536.984, total=   0.1s\n",
            "[CV] model__alpha=3.3000000000000003 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104511.21025283262, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8676.769508467056, tolerance: 4930.625720000001\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=3.3000000000000003, score=-969502.897, total=   0.1s\n",
            "[CV] model__alpha=3.3000000000000003 .................................\n",
            "[CV]  model__alpha=3.3000000000000003, score=-878747.740, total=   0.1s\n",
            "[CV] model__alpha=3.4000000000000004 .................................\n",
            "[CV]  model__alpha=3.4000000000000004, score=-11521852.495, total=   0.1s\n",
            "[CV] model__alpha=3.4000000000000004 .................................\n",
            "[CV]  model__alpha=3.4000000000000004, score=-1090783.538, total=   0.1s\n",
            "[CV] model__alpha=3.4000000000000004 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18614.094630811363, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15508.37137630023, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6625.3818885255605, tolerance: 4930.625720000001\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=3.4000000000000004, score=-1052859.454, total=   0.1s\n",
            "[CV] model__alpha=3.4000000000000004 .................................\n",
            "[CV]  model__alpha=3.4000000000000004, score=-950076.033, total=   0.1s\n",
            "[CV] model__alpha=3.4000000000000004 .................................\n",
            "[CV]  model__alpha=3.4000000000000004, score=-873653.437, total=   0.1s\n",
            "[CV] model__alpha=3.5000000000000004 .................................\n",
            "[CV]  model__alpha=3.5000000000000004, score=-11173161.619, total=   0.1s\n",
            "[CV] model__alpha=3.5000000000000004 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18794.948992586695, tolerance: 4371.369048387098\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4559.035692966543, tolerance: 4494.4464272\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6306.447994444519, tolerance: 4930.625720000001\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=3.5000000000000004, score=-1063869.927, total=   0.1s\n",
            "[CV] model__alpha=3.5000000000000004 .................................\n",
            "[CV]  model__alpha=3.5000000000000004, score=-1040147.885, total=   0.0s\n",
            "[CV] model__alpha=3.5000000000000004 .................................\n",
            "[CV]  model__alpha=3.5000000000000004, score=-930508.494, total=   0.1s\n",
            "[CV] model__alpha=3.5000000000000004 .................................\n",
            "[CV]  model__alpha=3.5000000000000004, score=-869573.099, total=   0.1s\n",
            "[CV] model__alpha=3.6 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16871.356650942937, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ............ model__alpha=3.6, score=-10576533.708, total=   0.1s\n",
            "[CV] model__alpha=3.6 ................................................\n",
            "[CV] ............. model__alpha=3.6, score=-1041487.135, total=   0.1s\n",
            "[CV] model__alpha=3.6 ................................................\n",
            "[CV] ............. model__alpha=3.6, score=-1030383.702, total=   0.0s\n",
            "[CV] model__alpha=3.6 ................................................\n",
            "[CV] .............. model__alpha=3.6, score=-909958.556, total=   0.1s\n",
            "[CV] model__alpha=3.6 ................................................\n",
            "[CV] .............. model__alpha=3.6, score=-865612.511, total=   0.1s\n",
            "[CV] model__alpha=3.7 ................................................\n",
            "[CV] ............. model__alpha=3.7, score=-9646538.301, total=   0.1s\n",
            "[CV] model__alpha=3.7 ................................................\n",
            "[CV] ............. model__alpha=3.7, score=-1022032.448, total=   0.0s\n",
            "[CV] model__alpha=3.7 ................................................\n",
            "[CV] ............. model__alpha=3.7, score=-1021687.216, total=   0.0s\n",
            "[CV] model__alpha=3.7 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19069.766958454624, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=3.7, score=-890108.583, total=   0.1s\n",
            "[CV] model__alpha=3.7 ................................................\n",
            "[CV] .............. model__alpha=3.7, score=-861729.479, total=   0.1s\n",
            "[CV] model__alpha=3.8000000000000003 .................................\n",
            "[CV]  model__alpha=3.8000000000000003, score=-8952789.328, total=   0.1s\n",
            "[CV] model__alpha=3.8000000000000003 .................................\n",
            "[CV]  model__alpha=3.8000000000000003, score=-1002834.929, total=   0.1s\n",
            "[CV] model__alpha=3.8000000000000003 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20291.00999371521, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=3.8000000000000003, score=-1012933.513, total=   0.1s\n",
            "[CV] model__alpha=3.8000000000000003 .................................\n",
            "[CV]  model__alpha=3.8000000000000003, score=-870839.408, total=   0.1s\n",
            "[CV] model__alpha=3.8000000000000003 .................................\n",
            "[CV]  model__alpha=3.8000000000000003, score=-857343.869, total=   0.0s\n",
            "[CV] model__alpha=3.9000000000000004 .................................\n",
            "[CV]  model__alpha=3.9000000000000004, score=-8469646.703, total=   0.1s\n",
            "[CV] model__alpha=3.9000000000000004 ................................."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21315.293819326907, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[CV]  model__alpha=3.9000000000000004, score=-984123.154, total=   0.1s\n",
            "[CV] model__alpha=3.9000000000000004 .................................\n",
            "[CV]  model__alpha=3.9000000000000004, score=-1003605.344, total=   0.0s\n",
            "[CV] model__alpha=3.9000000000000004 .................................\n",
            "[CV]  model__alpha=3.9000000000000004, score=-850574.332, total=   0.1s\n",
            "[CV] model__alpha=3.9000000000000004 .................................\n",
            "[CV]  model__alpha=3.9000000000000004, score=-853576.380, total=   0.1s\n",
            "[CV] model__alpha=4.0 ................................................\n",
            "[CV] ............. model__alpha=4.0, score=-8104980.953, total=   0.1s\n",
            "[CV] model__alpha=4.0 ................................................\n",
            "[CV] .............. model__alpha=4.0, score=-966591.829, total=   0.1s\n",
            "[CV] model__alpha=4.0 ................................................\n",
            "[CV] .............. model__alpha=4.0, score=-993272.339, total=   0.0s\n",
            "[CV] model__alpha=4.0 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24353.711338686757, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=4.0, score=-829344.874, total=   0.1s\n",
            "[CV] model__alpha=4.0 ................................................\n",
            "[CV] .............. model__alpha=4.0, score=-849797.017, total=   0.0s\n",
            "[CV] model__alpha=4.1 ................................................\n",
            "[CV] ............. model__alpha=4.1, score=-7651177.875, total=   0.1s\n",
            "[CV] model__alpha=4.1 ................................................\n",
            "[CV] .............. model__alpha=4.1, score=-949006.478, total=   0.1s\n",
            "[CV] model__alpha=4.1 ................................................\n",
            "[CV] .............. model__alpha=4.1, score=-982674.371, total=   0.0s\n",
            "[CV] model__alpha=4.1 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23640.174041480757, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=4.1, score=-810017.143, total=   0.1s\n",
            "[CV] model__alpha=4.1 ................................................\n",
            "[CV] .............. model__alpha=4.1, score=-846052.439, total=   0.0s\n",
            "[CV] model__alpha=4.2 ................................................\n",
            "[CV] ............. model__alpha=4.2, score=-7288814.762, total=   0.1s\n",
            "[CV] model__alpha=4.2 ................................................\n",
            "[CV] .............. model__alpha=4.2, score=-930232.165, total=   0.1s\n",
            "[CV] model__alpha=4.2 ................................................\n",
            "[CV] .............. model__alpha=4.2, score=-972267.756, total=   0.0s\n",
            "[CV] model__alpha=4.2 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24468.214203003794, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=4.2, score=-791582.901, total=   0.1s\n",
            "[CV] model__alpha=4.2 ................................................\n",
            "[CV] .............. model__alpha=4.2, score=-842555.206, total=   0.0s\n",
            "[CV] model__alpha=4.3 ................................................\n",
            "[CV] ............. model__alpha=4.3, score=-6973608.520, total=   0.1s\n",
            "[CV] model__alpha=4.3 ................................................\n",
            "[CV] .............. model__alpha=4.3, score=-913735.069, total=   0.1s\n",
            "[CV] model__alpha=4.3 ................................................\n",
            "[CV] .............. model__alpha=4.3, score=-962121.018, total=   0.0s\n",
            "[CV] model__alpha=4.3 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25124.371621663682, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=4.3, score=-773800.333, total=   0.1s\n",
            "[CV] model__alpha=4.3 ................................................\n",
            "[CV] .............. model__alpha=4.3, score=-838431.251, total=   0.0s\n",
            "[CV] model__alpha=4.3999999999999995 .................................\n",
            "[CV]  model__alpha=4.3999999999999995, score=-6672229.231, total=   0.1s\n",
            "[CV] model__alpha=4.3999999999999995 .................................\n",
            "[CV]  model__alpha=4.3999999999999995, score=-900931.056, total=   0.1s\n",
            "[CV] model__alpha=4.3999999999999995 .................................\n",
            "[CV]  model__alpha=4.3999999999999995, score=-953126.740, total=   0.0s\n",
            "[CV] model__alpha=4.3999999999999995 .................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29182.274543930776, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  model__alpha=4.3999999999999995, score=-755497.199, total=   0.1s\n",
            "[CV] model__alpha=4.3999999999999995 .................................\n",
            "[CV]  model__alpha=4.3999999999999995, score=-834474.927, total=   0.0s\n",
            "[CV] model__alpha=4.5 ................................................\n",
            "[CV] ............. model__alpha=4.5, score=-6341804.120, total=   0.1s\n",
            "[CV] model__alpha=4.5 ................................................\n",
            "[CV] .............. model__alpha=4.5, score=-888242.840, total=   0.1s\n",
            "[CV] model__alpha=4.5 ................................................\n",
            "[CV] .............. model__alpha=4.5, score=-944898.595, total=   0.0s\n",
            "[CV] model__alpha=4.5 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31426.084863658994, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=4.5, score=-738094.197, total=   0.1s\n",
            "[CV] model__alpha=4.5 ................................................\n",
            "[CV] .............. model__alpha=4.5, score=-829359.079, total=   0.0s\n",
            "[CV] model__alpha=4.6 ................................................\n",
            "[CV] ............. model__alpha=4.6, score=-6006381.693, total=   0.1s\n",
            "[CV] model__alpha=4.6 ................................................\n",
            "[CV] .............. model__alpha=4.6, score=-875623.233, total=   0.1s\n",
            "[CV] model__alpha=4.6 ................................................\n",
            "[CV] .............. model__alpha=4.6, score=-936866.305, total=   0.0s\n",
            "[CV] model__alpha=4.6 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33119.95692194812, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=4.6, score=-723938.613, total=   0.1s\n",
            "[CV] model__alpha=4.6 ................................................\n",
            "[CV] .............. model__alpha=4.6, score=-823876.267, total=   0.0s\n",
            "[CV] model__alpha=4.7 ................................................\n",
            "[CV] ............. model__alpha=4.7, score=-5542684.004, total=   0.1s\n",
            "[CV] model__alpha=4.7 ................................................\n",
            "[CV] .............. model__alpha=4.7, score=-862676.853, total=   0.1s\n",
            "[CV] model__alpha=4.7 ................................................\n",
            "[CV] .............. model__alpha=4.7, score=-928685.134, total=   0.0s\n",
            "[CV] model__alpha=4.7 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27052.938521377742, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=4.7, score=-712650.551, total=   0.0s\n",
            "[CV] model__alpha=4.7 ................................................\n",
            "[CV] .............. model__alpha=4.7, score=-818776.276, total=   0.0s\n",
            "[CV] model__alpha=4.8 ................................................\n",
            "[CV] ............. model__alpha=4.8, score=-4983951.054, total=   0.1s\n",
            "[CV] model__alpha=4.8 ................................................\n",
            "[CV] .............. model__alpha=4.8, score=-849321.749, total=   0.0s\n",
            "[CV] model__alpha=4.8 ................................................\n",
            "[CV] .............. model__alpha=4.8, score=-920533.234, total=   0.0s\n",
            "[CV] model__alpha=4.8 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14206.317287739366, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=4.8, score=-700688.720, total=   0.1s\n",
            "[CV] model__alpha=4.8 ................................................\n",
            "[CV] .............. model__alpha=4.8, score=-813686.707, total=   0.0s\n",
            "[CV] model__alpha=4.9 ................................................\n",
            "[CV] ............. model__alpha=4.9, score=-4544822.038, total=   0.1s\n",
            "[CV] model__alpha=4.9 ................................................\n",
            "[CV] .............. model__alpha=4.9, score=-835788.057, total=   0.0s\n",
            "[CV] model__alpha=4.9 ................................................\n",
            "[CV] .............. model__alpha=4.9, score=-911853.018, total=   0.0s\n",
            "[CV] model__alpha=4.9 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11132.147366499528, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=4.9, score=-685513.008, total=   0.1s\n",
            "[CV] model__alpha=4.9 ................................................\n",
            "[CV] .............. model__alpha=4.9, score=-808177.487, total=   0.0s\n",
            "[CV] model__alpha=5.0 ................................................\n",
            "[CV] ............. model__alpha=5.0, score=-4091382.620, total=   0.1s\n",
            "[CV] model__alpha=5.0 ................................................\n",
            "[CV] .............. model__alpha=5.0, score=-822574.189, total=   0.1s\n",
            "[CV] model__alpha=5.0 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12980.218328296207, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=5.0, score=-902584.452, total=   0.1s\n",
            "[CV] model__alpha=5.0 ................................................\n",
            "[CV] .............. model__alpha=5.0, score=-674912.722, total=   0.0s\n",
            "[CV] model__alpha=5.0 ................................................\n",
            "[CV] .............. model__alpha=5.0, score=-802722.920, total=   0.0s\n",
            "[CV] model__alpha=5.1 ................................................\n",
            "[CV] ............. model__alpha=5.1, score=-3656973.083, total=   0.1s\n",
            "[CV] model__alpha=5.1 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14873.447264028713, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=5.1, score=-808364.382, total=   0.1s\n",
            "[CV] model__alpha=5.1 ................................................\n",
            "[CV] .............. model__alpha=5.1, score=-892439.230, total=   0.0s\n",
            "[CV] model__alpha=5.1 ................................................\n",
            "[CV] .............. model__alpha=5.1, score=-665129.295, total=   0.0s\n",
            "[CV] model__alpha=5.1 ................................................\n",
            "[CV] .............. model__alpha=5.1, score=-797657.016, total=   0.0s\n",
            "[CV] model__alpha=5.2 ................................................\n",
            "[CV] ............. model__alpha=5.2, score=-3232161.435, total=   0.1s\n",
            "[CV] model__alpha=5.2 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16368.878685699776, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=5.2, score=-796425.530, total=   0.1s\n",
            "[CV] model__alpha=5.2 ................................................\n",
            "[CV] .............. model__alpha=5.2, score=-882267.641, total=   0.0s\n",
            "[CV] model__alpha=5.2 ................................................\n",
            "[CV] .............. model__alpha=5.2, score=-655513.434, total=   0.0s\n",
            "[CV] model__alpha=5.2 ................................................\n",
            "[CV] .............. model__alpha=5.2, score=-793046.935, total=   0.0s\n",
            "[CV] model__alpha=5.3 ................................................\n",
            "[CV] ............. model__alpha=5.3, score=-2837580.217, total=   0.1s\n",
            "[CV] model__alpha=5.3 ................................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15634.806383148767, tolerance: 4371.369048387098\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .............. model__alpha=5.3, score=-785357.652, total=   0.1s\n",
            "[CV] model__alpha=5.3 ................................................\n",
            "[CV] .............. model__alpha=5.3, score=-872209.232, total=   0.0s\n",
            "[CV] model__alpha=5.3 ................................................\n",
            "[CV] .............. model__alpha=5.3, score=-646175.063, total=   0.0s\n",
            "[CV] model__alpha=5.3 ................................................\n",
            "[CV] .............. model__alpha=5.3, score=-788658.141, total=   0.0s\n",
            "[CV] model__alpha=5.4 ................................................\n",
            "[CV] ............. model__alpha=5.4, score=-2607072.342, total=   0.1s\n",
            "[CV] model__alpha=5.4 ................................................\n",
            "[CV] .............. model__alpha=5.4, score=-776666.501, total=   0.0s\n",
            "[CV] model__alpha=5.4 ................................................\n",
            "[CV] .............. model__alpha=5.4, score=-862228.349, total=   0.0s\n",
            "[CV] model__alpha=5.4 ................................................\n",
            "[CV] .............. model__alpha=5.4, score=-637297.368, total=   0.0s\n",
            "[CV] model__alpha=5.4 ................................................\n",
            "[CV] .............. model__alpha=5.4, score=-784667.172, total=   0.0s\n",
            "[CV] model__alpha=5.5 ................................................\n",
            "[CV] ............. model__alpha=5.5, score=-2456670.546, total=   0.0s\n",
            "[CV] model__alpha=5.5 ................................................\n",
            "[CV] .............. model__alpha=5.5, score=-768065.613, total=   0.0s\n",
            "[CV] model__alpha=5.5 ................................................\n",
            "[CV] .............. model__alpha=5.5, score=-852365.973, total=   0.0s\n",
            "[CV] model__alpha=5.5 ................................................\n",
            "[CV] .............. model__alpha=5.5, score=-627935.502, total=   0.1s\n",
            "[CV] model__alpha=5.5 ................................................\n",
            "[CV] .............. model__alpha=5.5, score=-780721.914, total=   0.0s\n",
            "[CV] model__alpha=5.6 ................................................\n",
            "[CV] ............. model__alpha=5.6, score=-2282469.196, total=   0.0s\n",
            "[CV] model__alpha=5.6 ................................................\n",
            "[CV] .............. model__alpha=5.6, score=-759224.893, total=   0.0s\n",
            "[CV] model__alpha=5.6 ................................................\n",
            "[CV] .............. model__alpha=5.6, score=-843213.030, total=   0.0s\n",
            "[CV] model__alpha=5.6 ................................................\n",
            "[CV] .............. model__alpha=5.6, score=-619944.089, total=   0.0s\n",
            "[CV] model__alpha=5.6 ................................................\n",
            "[CV] .............. model__alpha=5.6, score=-777099.803, total=   0.0s\n",
            "[CV] model__alpha=5.7 ................................................\n",
            "[CV] ............. model__alpha=5.7, score=-2115508.515, total=   0.0s\n",
            "[CV] model__alpha=5.7 ................................................\n",
            "[CV] .............. model__alpha=5.7, score=-750629.257, total=   0.0s\n",
            "[CV] model__alpha=5.7 ................................................\n",
            "[CV] .............. model__alpha=5.7, score=-834935.607, total=   0.0s\n",
            "[CV] model__alpha=5.7 ................................................\n",
            "[CV] .............. model__alpha=5.7, score=-613918.179, total=   0.1s\n",
            "[CV] model__alpha=5.7 ................................................\n",
            "[CV] .............. model__alpha=5.7, score=-773815.843, total=   0.0s\n",
            "[CV] model__alpha=5.8 ................................................\n",
            "[CV] ............. model__alpha=5.8, score=-1959634.645, total=   0.0s\n",
            "[CV] model__alpha=5.8 ................................................\n",
            "[CV] .............. model__alpha=5.8, score=-744424.834, total=   0.0s\n",
            "[CV] model__alpha=5.8 ................................................\n",
            "[CV] .............. model__alpha=5.8, score=-827066.737, total=   0.0s\n",
            "[CV] model__alpha=5.8 ................................................\n",
            "[CV] .............. model__alpha=5.8, score=-607610.478, total=   0.1s\n",
            "[CV] model__alpha=5.8 ................................................\n",
            "[CV] .............. model__alpha=5.8, score=-770634.384, total=   0.0s\n",
            "[CV] model__alpha=5.9 ................................................\n",
            "[CV] ............. model__alpha=5.9, score=-1814504.560, total=   0.0s\n",
            "[CV] model__alpha=5.9 ................................................\n",
            "[CV] .............. model__alpha=5.9, score=-738794.657, total=   0.0s\n",
            "[CV] model__alpha=5.9 ................................................\n",
            "[CV] .............. model__alpha=5.9, score=-819710.987, total=   0.0s\n",
            "[CV] model__alpha=5.9 ................................................\n",
            "[CV] .............. model__alpha=5.9, score=-602294.541, total=   0.1s\n",
            "[CV] model__alpha=5.9 ................................................\n",
            "[CV] .............. model__alpha=5.9, score=-767048.217, total=   0.0s\n",
            "[CV] model__alpha=6.0 ................................................\n",
            "[CV] ............. model__alpha=6.0, score=-1689584.548, total=   0.0s\n",
            "[CV] model__alpha=6.0 ................................................\n",
            "[CV] .............. model__alpha=6.0, score=-733332.200, total=   0.0s\n",
            "[CV] model__alpha=6.0 ................................................\n",
            "[CV] .............. model__alpha=6.0, score=-812405.237, total=   0.0s\n",
            "[CV] model__alpha=6.0 ................................................\n",
            "[CV] .............. model__alpha=6.0, score=-597444.674, total=   0.1s\n",
            "[CV] model__alpha=6.0 ................................................\n",
            "[CV] .............. model__alpha=6.0, score=-763024.869, total=   0.0s\n",
            "[CV] model__alpha=6.1 ................................................\n",
            "[CV] ............. model__alpha=6.1, score=-1585409.233, total=   0.0s\n",
            "[CV] model__alpha=6.1 ................................................\n",
            "[CV] .............. model__alpha=6.1, score=-728209.727, total=   0.0s\n",
            "[CV] model__alpha=6.1 ................................................\n",
            "[CV] .............. model__alpha=6.1, score=-805303.932, total=   0.0s\n",
            "[CV] model__alpha=6.1 ................................................\n",
            "[CV] .............. model__alpha=6.1, score=-592924.648, total=   0.1s\n",
            "[CV] model__alpha=6.1 ................................................\n",
            "[CV] .............. model__alpha=6.1, score=-758990.492, total=   0.0s\n",
            "[CV] model__alpha=6.2 ................................................\n",
            "[CV] ............. model__alpha=6.2, score=-1490348.758, total=   0.0s\n",
            "[CV] model__alpha=6.2 ................................................\n",
            "[CV] .............. model__alpha=6.2, score=-723738.364, total=   0.0s\n",
            "[CV] model__alpha=6.2 ................................................\n",
            "[CV] .............. model__alpha=6.2, score=-798417.159, total=   0.0s\n",
            "[CV] model__alpha=6.2 ................................................\n",
            "[CV] .............. model__alpha=6.2, score=-588725.506, total=   0.1s\n",
            "[CV] model__alpha=6.2 ................................................\n",
            "[CV] .............. model__alpha=6.2, score=-754753.608, total=   0.0s\n",
            "[CV] model__alpha=6.3 ................................................\n",
            "[CV] ............. model__alpha=6.3, score=-1414605.250, total=   0.0s\n",
            "[CV] model__alpha=6.3 ................................................\n",
            "[CV] .............. model__alpha=6.3, score=-719424.322, total=   0.0s\n",
            "[CV] model__alpha=6.3 ................................................\n",
            "[CV] .............. model__alpha=6.3, score=-791688.902, total=   0.0s\n",
            "[CV] model__alpha=6.3 ................................................\n",
            "[CV] .............. model__alpha=6.3, score=-584500.704, total=   0.1s\n",
            "[CV] model__alpha=6.3 ................................................\n",
            "[CV] .............. model__alpha=6.3, score=-750190.303, total=   0.0s\n",
            "[CV] model__alpha=6.4 ................................................\n",
            "[CV] ............. model__alpha=6.4, score=-1344362.618, total=   0.0s\n",
            "[CV] model__alpha=6.4 ................................................\n",
            "[CV] .............. model__alpha=6.4, score=-715346.254, total=   0.0s\n",
            "[CV] model__alpha=6.4 ................................................\n",
            "[CV] .............. model__alpha=6.4, score=-784930.110, total=   0.0s\n",
            "[CV] model__alpha=6.4 ................................................\n",
            "[CV] .............. model__alpha=6.4, score=-580553.839, total=   0.1s\n",
            "[CV] model__alpha=6.4 ................................................\n",
            "[CV] .............. model__alpha=6.4, score=-745664.995, total=   0.0s\n",
            "[CV] model__alpha=6.5 ................................................\n",
            "[CV] ............. model__alpha=6.5, score=-1287885.212, total=   0.0s\n",
            "[CV] model__alpha=6.5 ................................................\n",
            "[CV] .............. model__alpha=6.5, score=-711491.905, total=   0.0s\n",
            "[CV] model__alpha=6.5 ................................................\n",
            "[CV] .............. model__alpha=6.5, score=-778207.625, total=   0.0s\n",
            "[CV] model__alpha=6.5 ................................................\n",
            "[CV] .............. model__alpha=6.5, score=-576619.113, total=   0.1s\n",
            "[CV] model__alpha=6.5 ................................................\n",
            "[CV] .............. model__alpha=6.5, score=-741087.944, total=   0.0s\n",
            "[CV] model__alpha=6.6 ................................................\n",
            "[CV] ............. model__alpha=6.6, score=-1232894.759, total=   0.0s\n",
            "[CV] model__alpha=6.6 ................................................\n",
            "[CV] .............. model__alpha=6.6, score=-707849.589, total=   0.0s\n",
            "[CV] model__alpha=6.6 ................................................\n",
            "[CV] .............. model__alpha=6.6, score=-771552.443, total=   0.0s\n",
            "[CV] model__alpha=6.6 ................................................\n",
            "[CV] .............. model__alpha=6.6, score=-572263.798, total=   0.1s\n",
            "[CV] model__alpha=6.6 ................................................\n",
            "[CV] .............. model__alpha=6.6, score=-736775.066, total=   0.0s\n",
            "[CV] model__alpha=6.7 ................................................\n",
            "[CV] ............. model__alpha=6.7, score=-1232655.173, total=   0.0s\n",
            "[CV] model__alpha=6.7 ................................................\n",
            "[CV] .............. model__alpha=6.7, score=-703950.223, total=   0.0s\n",
            "[CV] model__alpha=6.7 ................................................\n",
            "[CV] .............. model__alpha=6.7, score=-764978.599, total=   0.0s\n",
            "[CV] model__alpha=6.7 ................................................\n",
            "[CV] .............. model__alpha=6.7, score=-567967.974, total=   0.1s\n",
            "[CV] model__alpha=6.7 ................................................\n",
            "[CV] .............. model__alpha=6.7, score=-732755.597, total=   0.0s\n",
            "[CV] model__alpha=6.8 ................................................\n",
            "[CV] ............. model__alpha=6.8, score=-1271988.227, total=   0.1s\n",
            "[CV] model__alpha=6.8 ................................................\n",
            "[CV] .............. model__alpha=6.8, score=-699467.964, total=   0.0s\n",
            "[CV] model__alpha=6.8 ................................................\n",
            "[CV] .............. model__alpha=6.8, score=-758910.871, total=   0.0s\n",
            "[CV] model__alpha=6.8 ................................................\n",
            "[CV] .............. model__alpha=6.8, score=-563824.016, total=   0.1s\n",
            "[CV] model__alpha=6.8 ................................................\n",
            "[CV] .............. model__alpha=6.8, score=-728800.586, total=   0.0s\n",
            "[CV] model__alpha=6.9 ................................................\n",
            "[CV] ............. model__alpha=6.9, score=-1313691.485, total=   0.0s\n",
            "[CV] model__alpha=6.9 ................................................\n",
            "[CV] .............. model__alpha=6.9, score=-696026.546, total=   0.0s\n",
            "[CV] model__alpha=6.9 ................................................\n",
            "[CV] .............. model__alpha=6.9, score=-753298.739, total=   0.0s\n",
            "[CV] model__alpha=6.9 ................................................\n",
            "[CV] .............. model__alpha=6.9, score=-559417.842, total=   0.1s\n",
            "[CV] model__alpha=6.9 ................................................\n",
            "[CV] .............. model__alpha=6.9, score=-724906.018, total=   0.0s\n",
            "[CV] model__alpha=7.0 ................................................\n",
            "[CV] ............. model__alpha=7.0, score=-1358092.952, total=   0.0s\n",
            "[CV] model__alpha=7.0 ................................................\n",
            "[CV] .............. model__alpha=7.0, score=-692891.521, total=   0.0s\n",
            "[CV] model__alpha=7.0 ................................................\n",
            "[CV] .............. model__alpha=7.0, score=-747711.453, total=   0.0s\n",
            "[CV] model__alpha=7.0 ................................................\n",
            "[CV] .............. model__alpha=7.0, score=-554154.685, total=   0.1s\n",
            "[CV] model__alpha=7.0 ................................................\n",
            "[CV] .............. model__alpha=7.0, score=-721068.989, total=   0.0s\n",
            "[CV] model__alpha=7.1 ................................................\n",
            "[CV] ............. model__alpha=7.1, score=-1397053.099, total=   0.0s\n",
            "[CV] model__alpha=7.1 ................................................\n",
            "[CV] .............. model__alpha=7.1, score=-689950.013, total=   0.0s\n",
            "[CV] model__alpha=7.1 ................................................\n",
            "[CV] .............. model__alpha=7.1, score=-742201.646, total=   0.0s\n",
            "[CV] model__alpha=7.1 ................................................\n",
            "[CV] .............. model__alpha=7.1, score=-548920.711, total=   0.1s\n",
            "[CV] model__alpha=7.1 ................................................\n",
            "[CV] .............. model__alpha=7.1, score=-717292.168, total=   0.0s\n",
            "[CV] model__alpha=7.2 ................................................\n",
            "[CV] ............. model__alpha=7.2, score=-1428313.880, total=   0.0s\n",
            "[CV] model__alpha=7.2 ................................................\n",
            "[CV] .............. model__alpha=7.2, score=-683503.296, total=   0.0s\n",
            "[CV] model__alpha=7.2 ................................................\n",
            "[CV] .............. model__alpha=7.2, score=-736780.649, total=   0.0s\n",
            "[CV] model__alpha=7.2 ................................................\n",
            "[CV] .............. model__alpha=7.2, score=-543749.278, total=   0.1s\n",
            "[CV] model__alpha=7.2 ................................................\n",
            "[CV] .............. model__alpha=7.2, score=-713603.467, total=   0.0s\n",
            "[CV] model__alpha=7.3 ................................................\n",
            "[CV] ............. model__alpha=7.3, score=-1456634.792, total=   0.0s\n",
            "[CV] model__alpha=7.3 ................................................\n",
            "[CV] .............. model__alpha=7.3, score=-676397.096, total=   0.0s\n",
            "[CV] model__alpha=7.3 ................................................\n",
            "[CV] .............. model__alpha=7.3, score=-731361.926, total=   0.0s\n",
            "[CV] model__alpha=7.3 ................................................\n",
            "[CV] .............. model__alpha=7.3, score=-539377.607, total=   0.1s\n",
            "[CV] model__alpha=7.3 ................................................\n",
            "[CV] .............. model__alpha=7.3, score=-709968.138, total=   0.0s\n",
            "[CV] model__alpha=7.4 ................................................\n",
            "[CV] ............. model__alpha=7.4, score=-1461289.359, total=   0.0s\n",
            "[CV] model__alpha=7.4 ................................................\n",
            "[CV] .............. model__alpha=7.4, score=-668764.743, total=   0.0s\n",
            "[CV] model__alpha=7.4 ................................................\n",
            "[CV] .............. model__alpha=7.4, score=-725751.383, total=   0.0s\n",
            "[CV] model__alpha=7.4 ................................................\n",
            "[CV] .............. model__alpha=7.4, score=-535953.615, total=   0.0s\n",
            "[CV] model__alpha=7.4 ................................................\n",
            "[CV] .............. model__alpha=7.4, score=-706372.685, total=   0.0s\n",
            "[CV] model__alpha=7.5 ................................................\n",
            "[CV] ............. model__alpha=7.5, score=-1478754.344, total=   0.0s\n",
            "[CV] model__alpha=7.5 ................................................\n",
            "[CV] .............. model__alpha=7.5, score=-661302.227, total=   0.0s\n",
            "[CV] model__alpha=7.5 ................................................\n",
            "[CV] .............. model__alpha=7.5, score=-720461.087, total=   0.0s\n",
            "[CV] model__alpha=7.5 ................................................\n",
            "[CV] .............. model__alpha=7.5, score=-532703.302, total=   0.0s\n",
            "[CV] model__alpha=7.5 ................................................\n",
            "[CV] .............. model__alpha=7.5, score=-702824.439, total=   0.0s\n",
            "[CV] model__alpha=7.6 ................................................\n",
            "[CV] ............. model__alpha=7.6, score=-1494883.787, total=   0.0s\n",
            "[CV] model__alpha=7.6 ................................................\n",
            "[CV] .............. model__alpha=7.6, score=-653866.364, total=   0.0s\n",
            "[CV] model__alpha=7.6 ................................................\n",
            "[CV] .............. model__alpha=7.6, score=-715511.810, total=   0.0s\n",
            "[CV] model__alpha=7.6 ................................................\n",
            "[CV] .............. model__alpha=7.6, score=-529550.932, total=   0.0s\n",
            "[CV] model__alpha=7.6 ................................................\n",
            "[CV] .............. model__alpha=7.6, score=-699314.262, total=   0.0s\n",
            "[CV] model__alpha=7.7 ................................................\n",
            "[CV] ............. model__alpha=7.7, score=-1507516.697, total=   0.0s\n",
            "[CV] model__alpha=7.7 ................................................\n",
            "[CV] .............. model__alpha=7.7, score=-647102.256, total=   0.0s\n",
            "[CV] model__alpha=7.7 ................................................\n",
            "[CV] .............. model__alpha=7.7, score=-711037.149, total=   0.0s\n",
            "[CV] model__alpha=7.7 ................................................\n",
            "[CV] .............. model__alpha=7.7, score=-526393.823, total=   0.1s\n",
            "[CV] model__alpha=7.7 ................................................\n",
            "[CV] .............. model__alpha=7.7, score=-695785.401, total=   0.0s\n",
            "[CV] model__alpha=7.8 ................................................\n",
            "[CV] ............. model__alpha=7.8, score=-1478920.429, total=   0.0s\n",
            "[CV] model__alpha=7.8 ................................................\n",
            "[CV] .............. model__alpha=7.8, score=-641014.687, total=   0.0s\n",
            "[CV] model__alpha=7.8 ................................................\n",
            "[CV] .............. model__alpha=7.8, score=-707620.819, total=   0.0s\n",
            "[CV] model__alpha=7.8 ................................................\n",
            "[CV] .............. model__alpha=7.8, score=-523416.782, total=   0.0s\n",
            "[CV] model__alpha=7.8 ................................................\n",
            "[CV] .............. model__alpha=7.8, score=-692300.353, total=   0.0s\n",
            "[CV] model__alpha=7.9 ................................................\n",
            "[CV] ............. model__alpha=7.9, score=-1438046.752, total=   0.0s\n",
            "[CV] model__alpha=7.9 ................................................\n",
            "[CV] .............. model__alpha=7.9, score=-635935.547, total=   0.0s\n",
            "[CV] model__alpha=7.9 ................................................\n",
            "[CV] .............. model__alpha=7.9, score=-704161.625, total=   0.0s\n",
            "[CV] model__alpha=7.9 ................................................\n",
            "[CV] .............. model__alpha=7.9, score=-520518.061, total=   0.0s\n",
            "[CV] model__alpha=7.9 ................................................\n",
            "[CV] .............. model__alpha=7.9, score=-688923.267, total=   0.0s\n",
            "[CV] model__alpha=8.0 ................................................\n",
            "[CV] ............. model__alpha=8.0, score=-1398067.504, total=   0.0s\n",
            "[CV] model__alpha=8.0 ................................................\n",
            "[CV] .............. model__alpha=8.0, score=-631037.575, total=   0.0s\n",
            "[CV] model__alpha=8.0 ................................................\n",
            "[CV] .............. model__alpha=8.0, score=-700684.793, total=   0.0s\n",
            "[CV] model__alpha=8.0 ................................................\n",
            "[CV] .............. model__alpha=8.0, score=-517690.423, total=   0.0s\n",
            "[CV] model__alpha=8.0 ................................................\n",
            "[CV] .............. model__alpha=8.0, score=-685612.444, total=   0.0s\n",
            "[CV] model__alpha=8.1 ................................................\n",
            "[CV] ............. model__alpha=8.1, score=-1358853.996, total=   0.0s\n",
            "[CV] model__alpha=8.1 ................................................\n",
            "[CV] .............. model__alpha=8.1, score=-625496.114, total=   0.0s\n",
            "[CV] model__alpha=8.1 ................................................\n",
            "[CV] .............. model__alpha=8.1, score=-697693.778, total=   0.0s\n",
            "[CV] model__alpha=8.1 ................................................\n",
            "[CV] .............. model__alpha=8.1, score=-515030.594, total=   0.0s\n",
            "[CV] model__alpha=8.1 ................................................\n",
            "[CV] .............. model__alpha=8.1, score=-682350.671, total=   0.0s\n",
            "[CV] model__alpha=8.2 ................................................\n",
            "[CV] ............. model__alpha=8.2, score=-1320047.827, total=   0.0s\n",
            "[CV] model__alpha=8.2 ................................................\n",
            "[CV] .............. model__alpha=8.2, score=-620034.291, total=   0.0s\n",
            "[CV] model__alpha=8.2 ................................................\n",
            "[CV] .............. model__alpha=8.2, score=-693643.952, total=   0.0s\n",
            "[CV] model__alpha=8.2 ................................................\n",
            "[CV] .............. model__alpha=8.2, score=-513330.083, total=   0.0s\n",
            "[CV] model__alpha=8.2 ................................................\n",
            "[CV] .............. model__alpha=8.2, score=-679149.540, total=   0.0s\n",
            "[CV] model__alpha=8.3 ................................................\n",
            "[CV] ............. model__alpha=8.3, score=-1291524.080, total=   0.0s\n",
            "[CV] model__alpha=8.3 ................................................\n",
            "[CV] .............. model__alpha=8.3, score=-614607.625, total=   0.0s\n",
            "[CV] model__alpha=8.3 ................................................\n",
            "[CV] .............. model__alpha=8.3, score=-687754.190, total=   0.0s\n",
            "[CV] model__alpha=8.3 ................................................\n",
            "[CV] .............. model__alpha=8.3, score=-511616.680, total=   0.0s\n",
            "[CV] model__alpha=8.3 ................................................\n",
            "[CV] .............. model__alpha=8.3, score=-676030.865, total=   0.0s\n",
            "[CV] model__alpha=8.4 ................................................\n",
            "[CV] ............. model__alpha=8.4, score=-1267969.437, total=   0.0s\n",
            "[CV] model__alpha=8.4 ................................................\n",
            "[CV] .............. model__alpha=8.4, score=-609516.302, total=   0.0s\n",
            "[CV] model__alpha=8.4 ................................................\n",
            "[CV] .............. model__alpha=8.4, score=-681939.725, total=   0.0s\n",
            "[CV] model__alpha=8.4 ................................................\n",
            "[CV] .............. model__alpha=8.4, score=-509912.718, total=   0.0s\n",
            "[CV] model__alpha=8.4 ................................................\n",
            "[CV] .............. model__alpha=8.4, score=-673041.763, total=   0.0s\n",
            "[CV] model__alpha=8.5 ................................................\n",
            "[CV] ............. model__alpha=8.5, score=-1244335.727, total=   0.0s\n",
            "[CV] model__alpha=8.5 ................................................\n",
            "[CV] .............. model__alpha=8.5, score=-604103.067, total=   0.0s\n",
            "[CV] model__alpha=8.5 ................................................\n",
            "[CV] .............. model__alpha=8.5, score=-676511.723, total=   0.0s\n",
            "[CV] model__alpha=8.5 ................................................\n",
            "[CV] .............. model__alpha=8.5, score=-508152.678, total=   0.0s\n",
            "[CV] model__alpha=8.5 ................................................\n",
            "[CV] .............. model__alpha=8.5, score=-670224.358, total=   0.0s\n",
            "[CV] model__alpha=8.6 ................................................\n",
            "[CV] ............. model__alpha=8.6, score=-1219422.148, total=   0.0s\n",
            "[CV] model__alpha=8.6 ................................................\n",
            "[CV] .............. model__alpha=8.6, score=-598609.550, total=   0.0s\n",
            "[CV] model__alpha=8.6 ................................................\n",
            "[CV] .............. model__alpha=8.6, score=-671633.914, total=   0.0s\n",
            "[CV] model__alpha=8.6 ................................................\n",
            "[CV] .............. model__alpha=8.6, score=-506790.440, total=   0.0s\n",
            "[CV] model__alpha=8.6 ................................................\n",
            "[CV] .............. model__alpha=8.6, score=-667351.220, total=   0.0s\n",
            "[CV] model__alpha=8.7 ................................................\n",
            "[CV] ............. model__alpha=8.7, score=-1192452.996, total=   0.0s\n",
            "[CV] model__alpha=8.7 ................................................\n",
            "[CV] .............. model__alpha=8.7, score=-593199.356, total=   0.0s\n",
            "[CV] model__alpha=8.7 ................................................\n",
            "[CV] .............. model__alpha=8.7, score=-666849.913, total=   0.0s\n",
            "[CV] model__alpha=8.7 ................................................\n",
            "[CV] .............. model__alpha=8.7, score=-505735.439, total=   0.0s\n",
            "[CV] model__alpha=8.7 ................................................\n",
            "[CV] .............. model__alpha=8.7, score=-664579.413, total=   0.0s\n",
            "[CV] model__alpha=8.8 ................................................\n",
            "[CV] ............. model__alpha=8.8, score=-1167732.800, total=   0.0s\n",
            "[CV] model__alpha=8.8 ................................................\n",
            "[CV] .............. model__alpha=8.8, score=-587837.435, total=   0.0s\n",
            "[CV] model__alpha=8.8 ................................................\n",
            "[CV] .............. model__alpha=8.8, score=-662068.574, total=   0.0s\n",
            "[CV] model__alpha=8.8 ................................................\n",
            "[CV] .............. model__alpha=8.8, score=-504751.221, total=   0.0s\n",
            "[CV] model__alpha=8.8 ................................................\n",
            "[CV] .............. model__alpha=8.8, score=-662526.533, total=   0.0s\n",
            "[CV] model__alpha=8.9 ................................................\n",
            "[CV] ............. model__alpha=8.9, score=-1143545.815, total=   0.0s\n",
            "[CV] model__alpha=8.9 ................................................\n",
            "[CV] .............. model__alpha=8.9, score=-582856.309, total=   0.0s\n",
            "[CV] model__alpha=8.9 ................................................\n",
            "[CV] .............. model__alpha=8.9, score=-657208.336, total=   0.0s\n",
            "[CV] model__alpha=8.9 ................................................\n",
            "[CV] .............. model__alpha=8.9, score=-503840.216, total=   0.0s\n",
            "[CV] model__alpha=8.9 ................................................\n",
            "[CV] .............. model__alpha=8.9, score=-660814.247, total=   0.0s\n",
            "[CV] model__alpha=9.0 ................................................\n",
            "[CV] ............. model__alpha=9.0, score=-1119472.118, total=   0.0s\n",
            "[CV] model__alpha=9.0 ................................................\n",
            "[CV] .............. model__alpha=9.0, score=-578114.916, total=   0.0s\n",
            "[CV] model__alpha=9.0 ................................................\n",
            "[CV] .............. model__alpha=9.0, score=-652568.273, total=   0.0s\n",
            "[CV] model__alpha=9.0 ................................................\n",
            "[CV] .............. model__alpha=9.0, score=-502941.284, total=   0.0s\n",
            "[CV] model__alpha=9.0 ................................................\n",
            "[CV] .............. model__alpha=9.0, score=-659038.988, total=   0.0s\n",
            "[CV] model__alpha=9.1 ................................................\n",
            "[CV] ............. model__alpha=9.1, score=-1096278.336, total=   0.0s\n",
            "[CV] model__alpha=9.1 ................................................\n",
            "[CV] .............. model__alpha=9.1, score=-573287.520, total=   0.0s\n",
            "[CV] model__alpha=9.1 ................................................\n",
            "[CV] .............. model__alpha=9.1, score=-648072.645, total=   0.0s\n",
            "[CV] model__alpha=9.1 ................................................\n",
            "[CV] .............. model__alpha=9.1, score=-501743.094, total=   0.0s\n",
            "[CV] model__alpha=9.1 ................................................\n",
            "[CV] .............. model__alpha=9.1, score=-657282.701, total=   0.0s\n",
            "[CV] model__alpha=9.2 ................................................\n",
            "[CV] ............. model__alpha=9.2, score=-1073930.339, total=   0.0s\n",
            "[CV] model__alpha=9.2 ................................................\n",
            "[CV] .............. model__alpha=9.2, score=-568321.637, total=   0.0s\n",
            "[CV] model__alpha=9.2 ................................................\n",
            "[CV] .............. model__alpha=9.2, score=-643496.102, total=   0.0s\n",
            "[CV] model__alpha=9.2 ................................................\n",
            "[CV] .............. model__alpha=9.2, score=-500620.578, total=   0.0s\n",
            "[CV] model__alpha=9.2 ................................................\n",
            "[CV] .............. model__alpha=9.2, score=-655545.439, total=   0.0s\n",
            "[CV] model__alpha=9.3 ................................................\n",
            "[CV] ............. model__alpha=9.3, score=-1058678.849, total=   0.0s\n",
            "[CV] model__alpha=9.3 ................................................\n",
            "[CV] .............. model__alpha=9.3, score=-563795.556, total=   0.0s\n",
            "[CV] model__alpha=9.3 ................................................\n",
            "[CV] .............. model__alpha=9.3, score=-639192.423, total=   0.0s\n",
            "[CV] model__alpha=9.3 ................................................\n",
            "[CV] .............. model__alpha=9.3, score=-499571.966, total=   0.0s\n",
            "[CV] model__alpha=9.3 ................................................\n",
            "[CV] .............. model__alpha=9.3, score=-653828.341, total=   0.0s\n",
            "[CV] model__alpha=9.4 ................................................\n",
            "[CV] ............. model__alpha=9.4, score=-1043600.735, total=   0.0s\n",
            "[CV] model__alpha=9.4 ................................................\n",
            "[CV] .............. model__alpha=9.4, score=-559333.256, total=   0.0s\n",
            "[CV] model__alpha=9.4 ................................................\n",
            "[CV] .............. model__alpha=9.4, score=-634903.735, total=   0.0s\n",
            "[CV] model__alpha=9.4 ................................................\n",
            "[CV] .............. model__alpha=9.4, score=-498602.832, total=   0.0s\n",
            "[CV] model__alpha=9.4 ................................................\n",
            "[CV] .............. model__alpha=9.4, score=-652269.220, total=   0.0s\n",
            "[CV] model__alpha=9.5 ................................................\n",
            "[CV] ............. model__alpha=9.5, score=-1025767.282, total=   0.0s\n",
            "[CV] model__alpha=9.5 ................................................\n",
            "[CV] .............. model__alpha=9.5, score=-554699.409, total=   0.0s\n",
            "[CV] model__alpha=9.5 ................................................\n",
            "[CV] .............. model__alpha=9.5, score=-630791.167, total=   0.0s\n",
            "[CV] model__alpha=9.5 ................................................\n",
            "[CV] .............. model__alpha=9.5, score=-497762.045, total=   0.0s\n",
            "[CV] model__alpha=9.5 ................................................\n",
            "[CV] .............. model__alpha=9.5, score=-650771.564, total=   0.0s\n",
            "[CV] model__alpha=9.6 ................................................\n",
            "[CV] ............. model__alpha=9.6, score=-1006238.159, total=   0.0s\n",
            "[CV] model__alpha=9.6 ................................................\n",
            "[CV] .............. model__alpha=9.6, score=-550149.613, total=   0.0s\n",
            "[CV] model__alpha=9.6 ................................................\n",
            "[CV] .............. model__alpha=9.6, score=-626805.303, total=   0.0s\n",
            "[CV] model__alpha=9.6 ................................................\n",
            "[CV] .............. model__alpha=9.6, score=-496841.582, total=   0.0s\n",
            "[CV] model__alpha=9.6 ................................................\n",
            "[CV] .............. model__alpha=9.6, score=-649226.660, total=   0.0s\n",
            "[CV] model__alpha=9.700000000000001 ..................................\n",
            "[CV]  model__alpha=9.700000000000001, score=-961114.127, total=   0.0s\n",
            "[CV] model__alpha=9.700000000000001 ..................................\n",
            "[CV]  model__alpha=9.700000000000001, score=-545485.956, total=   0.0s\n",
            "[CV] model__alpha=9.700000000000001 ..................................\n",
            "[CV]  model__alpha=9.700000000000001, score=-623428.918, total=   0.0s\n",
            "[CV] model__alpha=9.700000000000001 ..................................\n",
            "[CV]  model__alpha=9.700000000000001, score=-495206.474, total=   0.0s\n",
            "[CV] model__alpha=9.700000000000001 ..................................\n",
            "[CV]  model__alpha=9.700000000000001, score=-647389.300, total=   0.0s\n",
            "[CV] model__alpha=9.8 ................................................\n",
            "[CV] .............. model__alpha=9.8, score=-901217.237, total=   0.0s\n",
            "[CV] model__alpha=9.8 ................................................\n",
            "[CV] .............. model__alpha=9.8, score=-540645.636, total=   0.0s\n",
            "[CV] model__alpha=9.8 ................................................\n",
            "[CV] .............. model__alpha=9.8, score=-620913.503, total=   0.0s\n",
            "[CV] model__alpha=9.8 ................................................\n",
            "[CV] .............. model__alpha=9.8, score=-493655.025, total=   0.0s\n",
            "[CV] model__alpha=9.8 ................................................\n",
            "[CV] .............. model__alpha=9.8, score=-645557.217, total=   0.0s\n",
            "[CV] model__alpha=9.9 ................................................\n",
            "[CV] .............. model__alpha=9.9, score=-851043.004, total=   0.0s\n",
            "[CV] model__alpha=9.9 ................................................\n",
            "[CV] .............. model__alpha=9.9, score=-535873.483, total=   0.0s\n",
            "[CV] model__alpha=9.9 ................................................\n",
            "[CV] .............. model__alpha=9.9, score=-618567.909, total=   0.0s\n",
            "[CV] model__alpha=9.9 ................................................\n",
            "[CV] .............. model__alpha=9.9, score=-492376.460, total=   0.0s\n",
            "[CV] model__alpha=9.9 ................................................\n",
            "[CV] .............. model__alpha=9.9, score=-643742.875, total=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 495 out of 495 | elapsed:   24.9s finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scaler',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('model',\n",
              "                                        Lasso(alpha=1.0, copy_X=True,\n",
              "                                              fit_intercept=True, max_iter=1000,\n",
              "                                              normalize=False, positive=False,\n",
              "                                              precompute=False,\n",
              "                                              random_state=None,\n",
              "                                              selection='cyclic', tol=0.0001,\n",
              "                                              warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprec...\n",
              "       2.7, 2.8, 2.9, 3. , 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9,\n",
              "       4. , 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5. , 5.1, 5.2,\n",
              "       5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6. , 6.1, 6.2, 6.3, 6.4, 6.5,\n",
              "       6.6, 6.7, 6.8, 6.9, 7. , 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8,\n",
              "       7.9, 8. , 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9. , 9.1,\n",
              "       9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9])},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_squared_error', verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqch2_IiXcUv",
        "outputId": "05d30ed6-30b3-4450-b274-e9c31eaf0a81"
      },
      "source": [
        "search.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model__alpha': 9.9}"
            ]
          },
          "metadata": {},
          "execution_count": 563
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpb0cbh2Xonz"
      },
      "source": [
        "coefficients = search.best_estimator_.named_steps['model'].coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UJpPA92YB37",
        "outputId": "a5769f5e-deca-4d2c-84cb-17ac1e47c04d"
      },
      "source": [
        "#Important features\n",
        "np.array(X_train.drop(columns=['PatientID']).columns.values)[importance > 0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Age', 'Chemotherapy', 'Tstage_1', 'Nstage_1', 'Nstage_3',\n",
              "       'TNMgroup_1', 'TNMgroup_2', 'TNM edition_8',\n",
              "       'HPV status (0=-, 1=+)_1.0', '0', '1', '2', '6', '7', '8', '17',\n",
              "       '22', '25', '27', '28', '30', '31', '35', '41', '47', '50', '52',\n",
              "       '55', '57', '62', '64', '78', '79', '81', '85', '86', '89', '90',\n",
              "       '91', '92', '95', '98', '101', '102', '105', '107', '109', '110',\n",
              "       '113', '115', '116', '121', '124', '128', '130', '135', '140',\n",
              "       '142', 'diagnostics_Image-original_Mean',\n",
              "       'diagnostics_Image-original_Maximum', 'original_shape_Flatness',\n",
              "       'original_shape_Maximum2DDiameterRow',\n",
              "       'original_shape_Maximum2DDiameterSlice',\n",
              "       'original_shape_Sphericity', 'original_firstorder_Skewness',\n",
              "       'original_gldm_DependenceVariance',\n",
              "       'original_glrlm_ShortRunHighGrayLevelEmphasis',\n",
              "       'original_glszm_GrayLevelNonUniformity',\n",
              "       'original_glszm_LargeAreaEmphasis',\n",
              "       'original_glszm_LargeAreaHighGrayLevelEmphasis',\n",
              "       'original_ngtdm_Contrast', 'original_ngtdm_Strength'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AlgH6xvYjjj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72707fbe-1a3f-4c64-c849-52a8c69e10ce"
      },
      "source": [
        "#Features to be removed \n",
        "remove_features = np.array(X_train.drop(columns=['PatientID']).columns.values)[importance == 0]\n",
        "print(remove_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tstage_2' 'Tstage_3' 'Nstage_2' 'TNMgroup_3' 'Tobacco_1.0' 'Alcohol_1.0'\n",
            " 'Gender (1=M,0=F)_1' 'Performance status_1.0' '3' '4' '5' '9' '10' '11'\n",
            " '12' '13' '14' '15' '16' '18' '19' '20' '21' '23' '24' '26' '29' '32'\n",
            " '33' '34' '36' '37' '38' '39' '40' '42' '43' '44' '45' '46' '48' '49'\n",
            " '51' '53' '54' '56' '58' '59' '60' '61' '63' '65' '66' '67' '68' '69'\n",
            " '70' '71' '72' '73' '74' '75' '76' '77' '80' '82' '83' '84' '87' '88'\n",
            " '93' '94' '96' '97' '99' '100' '103' '104' '106' '108' '111' '112' '114'\n",
            " '117' '118' '119' '120' '122' '123' '125' '126' '127' '129' '131' '132'\n",
            " '133' '134' '136' '137' '138' '139' '141' '143'\n",
            " 'diagnostics_Image-original_Minimum' 'diagnostics_Mask-original_VoxelNum'\n",
            " 'diagnostics_Mask-original_VolumeNum' 'original_shape_Elongation'\n",
            " 'original_shape_LeastAxisLength' 'original_shape_MajorAxisLength'\n",
            " 'original_shape_Maximum2DDiameterColumn'\n",
            " 'original_shape_Maximum3DDiameter' 'original_shape_MeshVolume'\n",
            " 'original_shape_MinorAxisLength' 'original_shape_SurfaceArea'\n",
            " 'original_shape_SurfaceVolumeRatio' 'original_shape_VoxelVolume'\n",
            " 'original_firstorder_10Percentile' 'original_firstorder_90Percentile'\n",
            " 'original_firstorder_Energy' 'original_firstorder_Entropy'\n",
            " 'original_firstorder_InterquartileRange' 'original_firstorder_Kurtosis'\n",
            " 'original_firstorder_Maximum' 'original_firstorder_MeanAbsoluteDeviation'\n",
            " 'original_firstorder_Mean' 'original_firstorder_Median'\n",
            " 'original_firstorder_Minimum' 'original_firstorder_Range'\n",
            " 'original_firstorder_RobustMeanAbsoluteDeviation'\n",
            " 'original_firstorder_RootMeanSquared' 'original_firstorder_TotalEnergy'\n",
            " 'original_firstorder_Uniformity' 'original_firstorder_Variance'\n",
            " 'original_glcm_Autocorrelation' 'original_glcm_ClusterProminence'\n",
            " 'original_glcm_ClusterShade' 'original_glcm_ClusterTendency'\n",
            " 'original_glcm_Contrast' 'original_glcm_Correlation'\n",
            " 'original_glcm_DifferenceAverage' 'original_glcm_DifferenceEntropy'\n",
            " 'original_glcm_DifferenceVariance' 'original_glcm_Id' 'original_glcm_Idm'\n",
            " 'original_glcm_Idmn' 'original_glcm_Idn' 'original_glcm_Imc1'\n",
            " 'original_glcm_Imc2' 'original_glcm_InverseVariance'\n",
            " 'original_glcm_JointAverage' 'original_glcm_JointEnergy'\n",
            " 'original_glcm_JointEntropy' 'original_glcm_MCC'\n",
            " 'original_glcm_MaximumProbability' 'original_glcm_SumAverage'\n",
            " 'original_glcm_SumEntropy' 'original_glcm_SumSquares'\n",
            " 'original_gldm_DependenceEntropy' 'original_gldm_DependenceNonUniformity'\n",
            " 'original_gldm_DependenceNonUniformityNormalized'\n",
            " 'original_gldm_GrayLevelNonUniformity' 'original_gldm_GrayLevelVariance'\n",
            " 'original_gldm_HighGrayLevelEmphasis'\n",
            " 'original_gldm_LargeDependenceEmphasis'\n",
            " 'original_gldm_LargeDependenceHighGrayLevelEmphasis'\n",
            " 'original_gldm_LargeDependenceLowGrayLevelEmphasis'\n",
            " 'original_gldm_LowGrayLevelEmphasis'\n",
            " 'original_gldm_SmallDependenceEmphasis'\n",
            " 'original_gldm_SmallDependenceHighGrayLevelEmphasis'\n",
            " 'original_gldm_SmallDependenceLowGrayLevelEmphasis'\n",
            " 'original_glrlm_GrayLevelNonUniformity'\n",
            " 'original_glrlm_GrayLevelNonUniformityNormalized'\n",
            " 'original_glrlm_GrayLevelVariance'\n",
            " 'original_glrlm_HighGrayLevelRunEmphasis'\n",
            " 'original_glrlm_LongRunEmphasis'\n",
            " 'original_glrlm_LongRunHighGrayLevelEmphasis'\n",
            " 'original_glrlm_LongRunLowGrayLevelEmphasis'\n",
            " 'original_glrlm_LowGrayLevelRunEmphasis' 'original_glrlm_RunEntropy'\n",
            " 'original_glrlm_RunLengthNonUniformity'\n",
            " 'original_glrlm_RunLengthNonUniformityNormalized'\n",
            " 'original_glrlm_RunPercentage' 'original_glrlm_RunVariance'\n",
            " 'original_glrlm_ShortRunEmphasis'\n",
            " 'original_glrlm_ShortRunLowGrayLevelEmphasis'\n",
            " 'original_glszm_GrayLevelNonUniformityNormalized'\n",
            " 'original_glszm_GrayLevelVariance'\n",
            " 'original_glszm_HighGrayLevelZoneEmphasis'\n",
            " 'original_glszm_LargeAreaLowGrayLevelEmphasis'\n",
            " 'original_glszm_LowGrayLevelZoneEmphasis'\n",
            " 'original_glszm_SizeZoneNonUniformity'\n",
            " 'original_glszm_SizeZoneNonUniformityNormalized'\n",
            " 'original_glszm_SmallAreaEmphasis'\n",
            " 'original_glszm_SmallAreaHighGrayLevelEmphasis'\n",
            " 'original_glszm_SmallAreaLowGrayLevelEmphasis'\n",
            " 'original_glszm_ZoneEntropy' 'original_glszm_ZonePercentage'\n",
            " 'original_glszm_ZoneVariance' 'original_ngtdm_Busyness'\n",
            " 'original_ngtdm_Coarseness' 'original_ngtdm_Complexity']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGQZGhsUYgqs"
      },
      "source": [
        "X_train = X_train.drop(remove_features, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67yUqpd22scQ"
      },
      "source": [
        " X_val = X_val.drop(remove_features, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtN9wxQXHPbf"
      },
      "source": [
        "# Drop those features from test set \n",
        "test_filtered = data_test.drop(remove_features, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sluXLWTFZ2Jw"
      },
      "source": [
        "# Filter highly correlated features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa3bRx3KU6-H"
      },
      "source": [
        "corr = pd.DataFrame(X_train).corr() \n",
        "correlated_features = []\n",
        "\n",
        "for i in range(len(corr .columns)):\n",
        "    for j in range(i):\n",
        "        if abs(corr.iloc[i, j]) > 0.9:\n",
        "            colname = corr.columns[i]\n",
        "            correlated_features.append(colname)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuTv9_i0VXlW",
        "outputId": "286373c7-3cc9-47ba-ca6a-eed6e8b56343"
      },
      "source": [
        "print(len(correlated_features))\n",
        "X_train = X_train.drop(columns=correlated_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26LRwLOOYX7i"
      },
      "source": [
        "X_val = X_val.drop(columns=correlated_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frHL8Jqm3N5B"
      },
      "source": [
        "#Test set \n",
        "TEST = test_filtered.drop(columns=correlated_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm_7mxuDsA6f"
      },
      "source": [
        "df_X_train = X_train \n",
        "df_X_val = X_val "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bog3i0EdrDav",
        "outputId": "80e8c08c-1fe3-44e6-9c76-921b3ec20106"
      },
      "source": [
        "#remove duplicated columns if any \n",
        "df_X_train = df_X_train.loc[:,~df_X_train.columns.duplicated()]\n",
        "df_X_val = df_X_val.loc[:,~df_X_val.columns.duplicated()]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Age  Chemotherapy  ...  original_ngtdm_Strength  PatientID\n",
            "26   81.0           0.0  ...                 0.001746    CHGJ053\n",
            "166  53.0           1.0  ...                 0.000000    CHUS026\n",
            "40   73.0           1.0  ...                 0.000000    CHGJ076\n",
            "13   52.0           1.0  ...                 0.000000    CHGJ031\n",
            "122  66.0           1.0  ...                 0.000000    CHUM059\n",
            "..    ...           ...  ...                      ...        ...\n",
            "67   58.0           1.0  ...                 0.000000    CHMR025\n",
            "192  68.0           1.0  ...                 0.000000    CHUS058\n",
            "117  70.0           1.0  ...                 0.000000    CHUM054\n",
            "47   67.0           1.0  ...                 0.000000    CHGJ085\n",
            "172  53.0           1.0  ...                 0.000000    CHUS035\n",
            "\n",
            "[156 rows x 61 columns]\n",
            "      Age  Chemotherapy  ...  original_ngtdm_Strength  PatientID\n",
            "96   52.0           1.0  ...                 0.000000    CHUM032\n",
            "202  62.0           1.0  ...                 0.000000    CHUS074\n",
            "169  77.0           0.0  ...                 0.000000    CHUS030\n",
            "136  59.0           1.0  ...                 0.061905    CHUP009\n",
            "182  74.0           1.0  ...                 0.000000    CHUS047\n",
            "..    ...           ...  ...                      ...        ...\n",
            "83   59.0           1.0  ...                 0.000000    CHUM015\n",
            "186  76.0           0.0  ...                 0.000000    CHUS051\n",
            "61   68.0           1.0  ...                 0.000000    CHMR014\n",
            "52   53.0           1.0  ...                 0.000000    CHGJ090\n",
            "66   64.0           1.0  ...                 0.000000    CHMR024\n",
            "\n",
            "[67 rows x 61 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEBxCt8m3XLc"
      },
      "source": [
        "TEST = TEST.loc[:,~TEST.columns.duplicated()]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yx2GDeeNbRH"
      },
      "source": [
        "# Format the train-val data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9xDinlXLXEv"
      },
      "source": [
        "X= pd.concat([df_X_train, df_X_val], ignore_index=False, sort=False)\n",
        "y = pd.concat([y_train, y_val], ignore_index=False, sort=False)\n",
        "X = X.sort_values(by = 'PatientID')\n",
        "#Merge the training data (Deepsurv/Deephit formatting)\n",
        "v = pd.merge(X, T, on = 'PatientID')\n",
        "df_train = pd.merge(v, E, on = 'PatientID' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "pAwW78_0p_jI",
        "outputId": "c311e6ec-2276-4a2f-e33d-ccfc6d283007"
      },
      "source": [
        "\n",
        "df_train.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Chemotherapy</th>\n",
              "      <th>Tstage_1</th>\n",
              "      <th>Nstage_1</th>\n",
              "      <th>Nstage_3</th>\n",
              "      <th>TNMgroup_1</th>\n",
              "      <th>TNMgroup_2</th>\n",
              "      <th>TNM edition_8</th>\n",
              "      <th>HPV status (0=-, 1=+)_1.0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>6</th>\n",
              "      <th>17</th>\n",
              "      <th>22</th>\n",
              "      <th>25</th>\n",
              "      <th>27</th>\n",
              "      <th>30</th>\n",
              "      <th>35</th>\n",
              "      <th>41</th>\n",
              "      <th>47</th>\n",
              "      <th>50</th>\n",
              "      <th>55</th>\n",
              "      <th>57</th>\n",
              "      <th>62</th>\n",
              "      <th>64</th>\n",
              "      <th>78</th>\n",
              "      <th>81</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>89</th>\n",
              "      <th>92</th>\n",
              "      <th>95</th>\n",
              "      <th>98</th>\n",
              "      <th>101</th>\n",
              "      <th>105</th>\n",
              "      <th>107</th>\n",
              "      <th>109</th>\n",
              "      <th>113</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>121</th>\n",
              "      <th>124</th>\n",
              "      <th>128</th>\n",
              "      <th>130</th>\n",
              "      <th>135</th>\n",
              "      <th>140</th>\n",
              "      <th>142</th>\n",
              "      <th>diagnostics_Image-original_Mean</th>\n",
              "      <th>diagnostics_Image-original_Maximum</th>\n",
              "      <th>original_shape_Flatness</th>\n",
              "      <th>original_shape_Maximum2DDiameterRow</th>\n",
              "      <th>original_shape_Maximum2DDiameterSlice</th>\n",
              "      <th>original_shape_Sphericity</th>\n",
              "      <th>original_firstorder_Skewness</th>\n",
              "      <th>original_gldm_DependenceVariance</th>\n",
              "      <th>original_glrlm_ShortRunHighGrayLevelEmphasis</th>\n",
              "      <th>original_glszm_GrayLevelNonUniformity</th>\n",
              "      <th>original_glszm_LargeAreaEmphasis</th>\n",
              "      <th>original_ngtdm_Contrast</th>\n",
              "      <th>original_ngtdm_Strength</th>\n",
              "      <th>Progression free survival</th>\n",
              "      <th>Progression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>62.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.516537</td>\n",
              "      <td>4.677599</td>\n",
              "      <td>4.624955</td>\n",
              "      <td>4.224866</td>\n",
              "      <td>4.700875</td>\n",
              "      <td>4.686843</td>\n",
              "      <td>4.626844</td>\n",
              "      <td>4.614446</td>\n",
              "      <td>4.849310</td>\n",
              "      <td>5.122953</td>\n",
              "      <td>5.309893</td>\n",
              "      <td>5.241373</td>\n",
              "      <td>6.780752</td>\n",
              "      <td>7.465911</td>\n",
              "      <td>10.846357</td>\n",
              "      <td>9.668675</td>\n",
              "      <td>6.361061</td>\n",
              "      <td>6.838998</td>\n",
              "      <td>6.032072</td>\n",
              "      <td>6.268207</td>\n",
              "      <td>16.234692</td>\n",
              "      <td>11.447547</td>\n",
              "      <td>14.006201</td>\n",
              "      <td>10.021963</td>\n",
              "      <td>15.616279</td>\n",
              "      <td>10.246559</td>\n",
              "      <td>12.044597</td>\n",
              "      <td>8.631438</td>\n",
              "      <td>8.504877</td>\n",
              "      <td>9.826251</td>\n",
              "      <td>10.345404</td>\n",
              "      <td>18.972225</td>\n",
              "      <td>18.887257</td>\n",
              "      <td>17.819248</td>\n",
              "      <td>18.964813</td>\n",
              "      <td>21.516360</td>\n",
              "      <td>21.336758</td>\n",
              "      <td>12.000441</td>\n",
              "      <td>1.373399</td>\n",
              "      <td>25.276834</td>\n",
              "      <td>0.724564</td>\n",
              "      <td>59.236813</td>\n",
              "      <td>50.119856</td>\n",
              "      <td>0.653100</td>\n",
              "      <td>-0.014760</td>\n",
              "      <td>14.024413</td>\n",
              "      <td>0.117039</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.209287e+09</td>\n",
              "      <td>8.268831e-10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>310</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>61.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.763744</td>\n",
              "      <td>5.127009</td>\n",
              "      <td>5.832845</td>\n",
              "      <td>6.006786</td>\n",
              "      <td>5.233970</td>\n",
              "      <td>5.746231</td>\n",
              "      <td>6.360868</td>\n",
              "      <td>5.064081</td>\n",
              "      <td>5.279643</td>\n",
              "      <td>5.970029</td>\n",
              "      <td>5.194820</td>\n",
              "      <td>5.590835</td>\n",
              "      <td>5.122812</td>\n",
              "      <td>4.948566</td>\n",
              "      <td>7.028618</td>\n",
              "      <td>7.296926</td>\n",
              "      <td>7.956578</td>\n",
              "      <td>7.159983</td>\n",
              "      <td>8.454244</td>\n",
              "      <td>8.175571</td>\n",
              "      <td>6.795301</td>\n",
              "      <td>6.839588</td>\n",
              "      <td>6.099201</td>\n",
              "      <td>8.324587</td>\n",
              "      <td>9.221310</td>\n",
              "      <td>7.355836</td>\n",
              "      <td>7.811171</td>\n",
              "      <td>6.867636</td>\n",
              "      <td>6.298368</td>\n",
              "      <td>5.925748</td>\n",
              "      <td>5.993853</td>\n",
              "      <td>11.847968</td>\n",
              "      <td>12.414833</td>\n",
              "      <td>10.108580</td>\n",
              "      <td>10.499516</td>\n",
              "      <td>9.841627</td>\n",
              "      <td>10.585178</td>\n",
              "      <td>7.337904</td>\n",
              "      <td>1.264393</td>\n",
              "      <td>13.264725</td>\n",
              "      <td>0.682694</td>\n",
              "      <td>28.792360</td>\n",
              "      <td>21.840330</td>\n",
              "      <td>0.741363</td>\n",
              "      <td>0.117102</td>\n",
              "      <td>23.021957</td>\n",
              "      <td>0.138217</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.696725e+07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2037</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>79.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.757696</td>\n",
              "      <td>10.516313</td>\n",
              "      <td>6.625793</td>\n",
              "      <td>5.719155</td>\n",
              "      <td>6.823604</td>\n",
              "      <td>7.575518</td>\n",
              "      <td>7.868264</td>\n",
              "      <td>7.430141</td>\n",
              "      <td>6.635969</td>\n",
              "      <td>7.052249</td>\n",
              "      <td>5.152165</td>\n",
              "      <td>4.750963</td>\n",
              "      <td>4.647209</td>\n",
              "      <td>4.730729</td>\n",
              "      <td>5.122075</td>\n",
              "      <td>5.399327</td>\n",
              "      <td>5.444087</td>\n",
              "      <td>5.371888</td>\n",
              "      <td>9.023921</td>\n",
              "      <td>7.049284</td>\n",
              "      <td>6.189453</td>\n",
              "      <td>5.393615</td>\n",
              "      <td>5.347976</td>\n",
              "      <td>10.045666</td>\n",
              "      <td>9.141331</td>\n",
              "      <td>6.937159</td>\n",
              "      <td>5.634351</td>\n",
              "      <td>5.473270</td>\n",
              "      <td>10.716955</td>\n",
              "      <td>11.187658</td>\n",
              "      <td>13.932541</td>\n",
              "      <td>13.512067</td>\n",
              "      <td>15.656564</td>\n",
              "      <td>14.850578</td>\n",
              "      <td>14.378210</td>\n",
              "      <td>13.490649</td>\n",
              "      <td>9.320275</td>\n",
              "      <td>8.961438</td>\n",
              "      <td>1.082563</td>\n",
              "      <td>11.854326</td>\n",
              "      <td>0.847292</td>\n",
              "      <td>19.416488</td>\n",
              "      <td>18.681542</td>\n",
              "      <td>0.815871</td>\n",
              "      <td>0.595335</td>\n",
              "      <td>25.564870</td>\n",
              "      <td>0.138641</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.909761e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1917</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>62.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.926895</td>\n",
              "      <td>6.223897</td>\n",
              "      <td>11.335909</td>\n",
              "      <td>7.386083</td>\n",
              "      <td>5.608498</td>\n",
              "      <td>6.489420</td>\n",
              "      <td>6.664249</td>\n",
              "      <td>6.159691</td>\n",
              "      <td>5.419880</td>\n",
              "      <td>6.170466</td>\n",
              "      <td>6.592583</td>\n",
              "      <td>6.201656</td>\n",
              "      <td>5.947432</td>\n",
              "      <td>5.130398</td>\n",
              "      <td>4.374220</td>\n",
              "      <td>4.776738</td>\n",
              "      <td>4.364235</td>\n",
              "      <td>4.993643</td>\n",
              "      <td>5.327912</td>\n",
              "      <td>5.585537</td>\n",
              "      <td>4.437806</td>\n",
              "      <td>4.613768</td>\n",
              "      <td>4.473212</td>\n",
              "      <td>4.463800</td>\n",
              "      <td>4.687502</td>\n",
              "      <td>4.762361</td>\n",
              "      <td>4.828611</td>\n",
              "      <td>5.260072</td>\n",
              "      <td>6.296486</td>\n",
              "      <td>8.522223</td>\n",
              "      <td>7.629566</td>\n",
              "      <td>11.798074</td>\n",
              "      <td>13.594780</td>\n",
              "      <td>14.408480</td>\n",
              "      <td>14.528991</td>\n",
              "      <td>14.322064</td>\n",
              "      <td>12.642089</td>\n",
              "      <td>8.799846</td>\n",
              "      <td>1.000646</td>\n",
              "      <td>11.845998</td>\n",
              "      <td>0.491382</td>\n",
              "      <td>33.734256</td>\n",
              "      <td>22.561028</td>\n",
              "      <td>0.768779</td>\n",
              "      <td>0.732431</td>\n",
              "      <td>21.802403</td>\n",
              "      <td>0.120181</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.189990e+07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1377</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.633841</td>\n",
              "      <td>6.786539</td>\n",
              "      <td>6.528471</td>\n",
              "      <td>6.795995</td>\n",
              "      <td>5.334478</td>\n",
              "      <td>4.973587</td>\n",
              "      <td>4.218722</td>\n",
              "      <td>3.679292</td>\n",
              "      <td>4.851692</td>\n",
              "      <td>5.326476</td>\n",
              "      <td>5.255210</td>\n",
              "      <td>5.322794</td>\n",
              "      <td>5.271499</td>\n",
              "      <td>5.247312</td>\n",
              "      <td>10.395865</td>\n",
              "      <td>11.360767</td>\n",
              "      <td>6.213783</td>\n",
              "      <td>7.763341</td>\n",
              "      <td>12.968037</td>\n",
              "      <td>14.299929</td>\n",
              "      <td>8.522232</td>\n",
              "      <td>7.464240</td>\n",
              "      <td>9.801277</td>\n",
              "      <td>10.843600</td>\n",
              "      <td>15.208096</td>\n",
              "      <td>10.864079</td>\n",
              "      <td>9.804054</td>\n",
              "      <td>8.416535</td>\n",
              "      <td>7.765898</td>\n",
              "      <td>8.176993</td>\n",
              "      <td>7.567304</td>\n",
              "      <td>12.303373</td>\n",
              "      <td>13.344452</td>\n",
              "      <td>12.757805</td>\n",
              "      <td>13.570099</td>\n",
              "      <td>16.900093</td>\n",
              "      <td>13.166973</td>\n",
              "      <td>8.979172</td>\n",
              "      <td>1.152449</td>\n",
              "      <td>14.143359</td>\n",
              "      <td>0.676817</td>\n",
              "      <td>20.880613</td>\n",
              "      <td>22.203603</td>\n",
              "      <td>0.761991</td>\n",
              "      <td>0.463448</td>\n",
              "      <td>26.288956</td>\n",
              "      <td>0.156158</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.225344e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1072</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Age  Chemotherapy  ...  Progression free survival  Progression\n",
              "0  62.0           1.0  ...                        310            1\n",
              "1  61.0           1.0  ...                       2037            0\n",
              "2  79.0           1.0  ...                       1917            0\n",
              "3  62.0           1.0  ...                       1377            0\n",
              "4  56.0           1.0  ...                       1072            0\n",
              "\n",
              "[5 rows x 62 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 405
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTUHw04JLJvA"
      },
      "source": [
        "T = endpoint_data[['PatientID','Progression free survival']]\n",
        "E = endpoint_data[['PatientID','Progression']]\n",
        "T = pd.DataFrame(T)\n",
        "E = pd.DataFrame(E)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJtZzYoaLJ23"
      },
      "source": [
        "np.random.seed(1234)\n",
        "_ = torch.manual_seed(23)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKu0v3L3LJ-U"
      },
      "source": [
        "df_val = df_train.sample(frac=0.2)\n",
        "df_train = df_train.drop(df_val.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChgaACjZFqfu"
      },
      "source": [
        "features = [x for x in df_train.keys() if x not in [ 'PatientID','Progression free survival', 'Progression']]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "x_train = np.zeros((len(df_train), len(features)))\n",
        "for i, f in enumerate(features):\n",
        "  x_train[:, i] = df_train[f]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maZv88GuF6kZ"
      },
      "source": [
        "features = [x for x in df_val.keys() if x not in ['PatientID', 'Progression free survival', 'Progression']]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "x_val = np.zeros((len(df_val), len(features)))\n",
        "for i, f in enumerate(features):\n",
        "  x_val[:, i] = df_val[f]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxb-HKZzJGP8"
      },
      "source": [
        "features = [x for x in TEST.keys() if x not in ['PatientID']]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "x_test = np.zeros((len(TEST), len(features)))\n",
        "for i, f in enumerate(features):\n",
        "  x_test[:, i] = TEST[f]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlUCTWOrklq5"
      },
      "source": [
        "x_train = np.array(x_train.astype('float32'))\n",
        "x_val = np.array(x_val.astype('float32'))\n",
        "x_test = np.array(x_test.astype('float32'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pObF11ynM9gQ"
      },
      "source": [
        "times_val = df_val['Progression free survival'].values\n",
        "events_val = df_val['Progression'].values\n",
        "y_val = (times_val, events_val)\n",
        "\n",
        "\n",
        "times_train = df_train['Progression free survival'].values\n",
        "events_train = df_train['Progression'].values\n",
        "y_train = (times_train, events_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC3bDM8HJ_Lk"
      },
      "source": [
        "# **2. Model Training** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiLkxQWi3eQ8"
      },
      "source": [
        "## **Random Survival Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ubGQ9rslkvL"
      },
      "source": [
        "from xgbse.converters import convert_to_structured\n",
        "\n",
        "Yt = convert_to_structured(x_train.iloc[:,-1], x_train.iloc[:,-2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xpCAiOch4vi",
        "outputId": "0ccd204c-aa64-4bc4-abb7-9be5657c076d"
      },
      "source": [
        "from sksurv.ensemble import RandomSurvivalForest\n",
        "from sklearn.model_selection import cross_validate\n",
        "params = {'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 10}\n",
        "rsf = RandomSurvivalForest(n_estimators = params['n_estimators'],\n",
        "                           min_samples_split = params['min_samples_split'],\n",
        "                           min_samples_leaf = params['min_samples_leaf'],\n",
        "                           max_features=\"sqrt\",\n",
        "                           n_jobs=-1\n",
        "                           )\n",
        "print(cross_validate(rsf, x_train, Yt, cv=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.0458045 , 0.0399332 , 0.04328966, 0.0432303 , 0.03729463]), 'score_time': array([0.10378766, 0.10326719, 0.10326123, 0.10340166, 0.10331011]), 'test_score': array([0.6090535 , 0.4691358 , 0.63225806, 0.50816993, 0.76666667])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmZW9QxabKnC"
      },
      "source": [
        "# **CoxPH Survival**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfrnPvwG2B8y"
      },
      "source": [
        "from lifelines import CoxPHFitter, WeibullAFTFitter , LogNormalAFTFitter, LogLogisticAFTFitter , PiecewiseExponentialRegressionFitter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6RZGRmq5vbM"
      },
      "source": [
        "train_df=[]\n",
        "yt = pd.DataFrame(y_train).transpose()\n",
        "ytrain = yt.set_axis(['Progression free survival', 'Progression'], axis=1, inplace=False)\n",
        "train_df = pd.merge(pd.DataFrame(x_train),ytrain, left_index=True, right_index=True)\n",
        "\n",
        "yv = pd.DataFrame(y_val).transpose()\n",
        "yval = yv.set_axis(['Progression free survival', 'Progression'], axis=1, inplace=False)\n",
        "val_df = pd.merge(pd.DataFrame(x_val),yval, left_index=True, right_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TVznBy9j2HiB",
        "outputId": "82e7060f-1c65-4a5b-c62c-3a558def1a19"
      },
      "source": [
        "cph10 =  CoxPHFitter().fit(train_df,duration_col = 'Progression free survival', event_col='Progression') \n",
        "cph10.print_summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/latex": "\\begin{tabular}{lrrrrrrrrrr}\n\\toprule\n{} &  coef &  exp(coef) &  se(coef) &  coef lower 95\\% &  coef upper 95\\% &  exp(coef) lower 95\\% &  exp(coef) upper 95\\% &     z &    p &  -log2(p) \\\\\ncovariate &       &            &           &                 &                 &                      &                      &       &      &           \\\\\n\\midrule\n0         &  0.02 &       1.02 &      0.03 &           -0.03 &            0.07 &                 0.97 &                 1.08 &  0.70 & 0.49 &      1.04 \\\\\n1         & -0.94 &       0.39 &      1.12 &           -3.14 &            1.25 &                 0.04 &                 3.49 & -0.84 & 0.40 &      1.33 \\\\\n2         & -0.60 &       0.55 &      0.76 &           -2.09 &            0.89 &                 0.12 &                 2.44 & -0.79 & 0.43 &      1.22 \\\\\n3         &  1.60 &       4.94 &      0.96 &           -0.29 &            3.49 &                 0.75 &                32.75 &  1.66 & 0.10 &      3.36 \\\\\n4         &  1.04 &       2.82 &      0.91 &           -0.75 &            2.83 &                 0.47 &                16.90 &  1.13 & 0.26 &      1.96 \\\\\n5         & -0.40 &       0.67 &      1.22 &           -2.78 &            1.98 &                 0.06 &                 7.24 & -0.33 & 0.74 &      0.43 \\\\\n6         & -2.16 &       0.12 &      1.07 &           -4.25 &           -0.06 &                 0.01 &                 0.94 & -2.02 & 0.04 &      4.52 \\\\\n7         &  1.95 &       7.01 &      0.90 &            0.18 &            3.72 &                 1.19 &                41.16 &  2.16 & 0.03 &      5.01 \\\\\n8         & -1.09 &       0.33 &      0.59 &           -2.26 &            0.07 &                 0.10 &                 1.07 & -1.84 & 0.07 &      3.94 \\\\\n9         & -0.13 &       0.88 &      0.12 &           -0.36 &            0.10 &                 0.70 &                 1.11 & -1.10 & 0.27 &      1.89 \\\\\n10        &  0.01 &       1.01 &      0.17 &           -0.33 &            0.35 &                 0.72 &                 1.42 &  0.04 & 0.97 &      0.04 \\\\\n11        &  0.40 &       1.49 &      0.17 &            0.07 &            0.72 &                 1.07 &                 2.06 &  2.38 & 0.02 &      5.85 \\\\\n12        & -0.19 &       0.83 &      0.15 &           -0.47 &            0.10 &                 0.62 &                 1.10 & -1.29 & 0.20 &      2.34 \\\\\n13        &  0.12 &       1.13 &      0.21 &           -0.29 &            0.54 &                 0.75 &                 1.71 &  0.57 & 0.57 &      0.82 \\\\\n14        & -0.24 &       0.78 &      0.29 &           -0.81 &            0.33 &                 0.44 &                 1.38 & -0.84 & 0.40 &      1.32 \\\\\n15        & -0.02 &       0.98 &      0.27 &           -0.54 &            0.51 &                 0.58 &                 1.67 & -0.06 & 0.95 &      0.07 \\\\\n16        &  0.30 &       1.36 &      0.17 &           -0.04 &            0.64 &                 0.96 &                 1.91 &  1.75 & 0.08 &      3.65 \\\\\n17        & -0.30 &       0.74 &      0.17 &           -0.64 &            0.04 &                 0.53 &                 1.04 & -1.75 & 0.08 &      3.63 \\\\\n18        &  0.01 &       1.01 &      0.15 &           -0.29 &            0.31 &                 0.75 &                 1.36 &  0.08 & 0.94 &      0.09 \\\\\n19        & -0.12 &       0.88 &      0.20 &           -0.51 &            0.26 &                 0.60 &                 1.29 & -0.64 & 0.52 &      0.94 \\\\\n20        &  0.14 &       1.15 &      0.15 &           -0.15 &            0.43 &                 0.86 &                 1.53 &  0.97 & 0.33 &      1.58 \\\\\n21        &  0.38 &       1.46 &      0.20 &           -0.02 &            0.78 &                 0.98 &                 2.17 &  1.86 & 0.06 &      4.00 \\\\\n22        & -0.15 &       0.86 &      0.25 &           -0.63 &            0.33 &                 0.53 &                 1.39 & -0.60 & 0.55 &      0.87 \\\\\n23        &  0.18 &       1.20 &      0.26 &           -0.32 &            0.68 &                 0.72 &                 1.98 &  0.70 & 0.49 &      1.04 \\\\\n24        & -0.19 &       0.82 &      0.26 &           -0.70 &            0.31 &                 0.50 &                 1.36 & -0.76 & 0.45 &      1.16 \\\\\n25        &  0.09 &       1.10 &      0.15 &           -0.20 &            0.39 &                 0.82 &                 1.48 &  0.62 & 0.53 &      0.91 \\\\\n26        & -0.23 &       0.80 &      0.21 &           -0.64 &            0.18 &                 0.53 &                 1.20 & -1.10 & 0.27 &      1.88 \\\\\n27        &  0.25 &       1.28 &      0.27 &           -0.28 &            0.77 &                 0.76 &                 2.16 &  0.92 & 0.36 &      1.48 \\\\\n28        & -0.37 &       0.69 &      0.20 &           -0.78 &            0.03 &                 0.46 &                 1.03 & -1.83 & 0.07 &      3.88 \\\\\n29        &  0.52 &       1.69 &      0.12 &            0.30 &            0.75 &                 1.35 &                 2.12 &  4.53 & 0.00 &     17.34 \\\\\n30        & -0.50 &       0.61 &      0.18 &           -0.85 &           -0.14 &                 0.43 &                 0.87 & -2.74 & 0.01 &      7.33 \\\\\n31        &  0.67 &       1.96 &      0.19 &            0.30 &            1.04 &                 1.35 &                 2.83 &  3.56 & 0.00 &     11.39 \\\\\n32        &  0.12 &       1.13 &      0.13 &           -0.13 &            0.37 &                 0.88 &                 1.45 &  0.96 & 0.34 &      1.58 \\\\\n33        & -0.56 &       0.57 &      0.20 &           -0.95 &           -0.18 &                 0.39 &                 0.84 & -2.85 & 0.00 &      7.84 \\\\\n34        &  0.19 &       1.21 &      0.18 &           -0.16 &            0.55 &                 0.85 &                 1.73 &  1.07 & 0.29 &      1.81 \\\\\n35        & -0.12 &       0.88 &      0.20 &           -0.52 &            0.27 &                 0.59 &                 1.31 & -0.62 & 0.54 &      0.89 \\\\\n36        &  0.21 &       1.23 &      0.20 &           -0.18 &            0.60 &                 0.83 &                 1.81 &  1.03 & 0.30 &      1.73 \\\\\n37        & -0.26 &       0.77 &      0.16 &           -0.58 &            0.06 &                 0.56 &                 1.07 & -1.57 & 0.12 &      3.10 \\\\\n38        &  0.47 &       1.60 &      0.20 &            0.07 &            0.86 &                 1.08 &                 2.37 &  2.33 & 0.02 &      5.66 \\\\\n39        & -0.29 &       0.75 &      0.18 &           -0.65 &            0.06 &                 0.52 &                 1.06 & -1.62 & 0.10 &      3.26 \\\\\n40        &  0.25 &       1.29 &      0.15 &           -0.04 &            0.54 &                 0.96 &                 1.72 &  1.71 & 0.09 &      3.51 \\\\\n41        &  0.10 &       1.11 &      0.18 &           -0.25 &            0.45 &                 0.78 &                 1.57 &  0.57 & 0.57 &      0.82 \\\\\n42        &  0.10 &       1.11 &      0.20 &           -0.29 &            0.50 &                 0.75 &                 1.64 &  0.52 & 0.60 &      0.73 \\\\\n43        & -0.50 &       0.61 &      0.22 &           -0.93 &           -0.08 &                 0.40 &                 0.93 & -2.31 & 0.02 &      5.58 \\\\\n44        &  0.15 &       1.17 &      0.13 &           -0.10 &            0.41 &                 0.90 &                 1.50 &  1.18 & 0.24 &      2.08 \\\\\n45        &  0.07 &       1.08 &      0.09 &           -0.09 &            0.24 &                 0.91 &                 1.27 &  0.87 & 0.38 &      1.38 \\\\\n46        & -0.02 &       0.98 &      0.10 &           -0.22 &            0.18 &                 0.80 &                 1.20 & -0.18 & 0.86 &      0.22 \\\\\n47        &  0.59 &       1.81 &      1.33 &           -2.02 &            3.21 &                 0.13 &                24.66 &  0.44 & 0.66 &      0.60 \\\\\n48        &  0.02 &       1.02 &      0.06 &           -0.09 &            0.13 &                 0.92 &                 1.14 &  0.42 & 0.68 &      0.56 \\\\\n49        & -1.68 &       0.19 &      2.88 &           -7.32 &            3.97 &                 0.00 &                52.97 & -0.58 & 0.56 &      0.84 \\\\\n50        & -0.03 &       0.97 &      0.04 &           -0.10 &            0.04 &                 0.91 &                 1.04 & -0.77 & 0.44 &      1.18 \\\\\n51        &  0.08 &       1.09 &      0.04 &            0.01 &            0.16 &                 1.01 &                 1.17 &  2.14 & 0.03 &      4.95 \\\\\n53        & -1.83 &       0.16 &      0.82 &           -3.43 &           -0.23 &                 0.03 &                 0.79 & -2.24 & 0.02 &      5.33 \\\\\n54        &  0.21 &       1.24 &      0.11 &           -0.00 &            0.43 &                 1.00 &                 1.54 &  1.94 & 0.05 &      4.27 \\\\\n56        & -2.13 &       0.12 &      1.53 &           -5.13 &            0.86 &                 0.01 &                 2.36 & -1.40 & 0.16 &      2.62 \\\\\n\\bottomrule\n\\end{tabular}\n",
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <td>lifelines.CoxPHFitter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>duration col</th>\n",
              "      <td>'Progression free survival'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>event col</th>\n",
              "      <td>'Progression'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>baseline estimation</th>\n",
              "      <td>breslow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number of observations</th>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number of events observed</th>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>partial log-likelihood</th>\n",
              "      <td>-177.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time fit was run</th>\n",
              "      <td>2021-09-15 08:38:32 UTC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th style=\"min-width: 12px;\"></th>\n",
              "      <th style=\"min-width: 12px;\">coef</th>\n",
              "      <th style=\"min-width: 12px;\">exp(coef)</th>\n",
              "      <th style=\"min-width: 12px;\">se(coef)</th>\n",
              "      <th style=\"min-width: 12px;\">coef lower 95%</th>\n",
              "      <th style=\"min-width: 12px;\">coef upper 95%</th>\n",
              "      <th style=\"min-width: 12px;\">exp(coef) lower 95%</th>\n",
              "      <th style=\"min-width: 12px;\">exp(coef) upper 95%</th>\n",
              "      <th style=\"min-width: 12px;\">z</th>\n",
              "      <th style=\"min-width: 12px;\">p</th>\n",
              "      <th style=\"min-width: 12px;\">-log2(p)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.02</td>\n",
              "      <td>1.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.97</td>\n",
              "      <td>1.08</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.49</td>\n",
              "      <td>1.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.94</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.12</td>\n",
              "      <td>-3.14</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.04</td>\n",
              "      <td>3.49</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.60</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.76</td>\n",
              "      <td>-2.09</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.12</td>\n",
              "      <td>2.44</td>\n",
              "      <td>-0.79</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.60</td>\n",
              "      <td>4.94</td>\n",
              "      <td>0.96</td>\n",
              "      <td>-0.29</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.75</td>\n",
              "      <td>32.75</td>\n",
              "      <td>1.66</td>\n",
              "      <td>0.10</td>\n",
              "      <td>3.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.04</td>\n",
              "      <td>2.82</td>\n",
              "      <td>0.91</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>2.83</td>\n",
              "      <td>0.47</td>\n",
              "      <td>16.90</td>\n",
              "      <td>1.13</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.40</td>\n",
              "      <td>0.67</td>\n",
              "      <td>1.22</td>\n",
              "      <td>-2.78</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.06</td>\n",
              "      <td>7.24</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-2.16</td>\n",
              "      <td>0.12</td>\n",
              "      <td>1.07</td>\n",
              "      <td>-4.25</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.94</td>\n",
              "      <td>-2.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>4.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.95</td>\n",
              "      <td>7.01</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.18</td>\n",
              "      <td>3.72</td>\n",
              "      <td>1.19</td>\n",
              "      <td>41.16</td>\n",
              "      <td>2.16</td>\n",
              "      <td>0.03</td>\n",
              "      <td>5.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-1.09</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.59</td>\n",
              "      <td>-2.26</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1.07</td>\n",
              "      <td>-1.84</td>\n",
              "      <td>0.07</td>\n",
              "      <td>3.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.12</td>\n",
              "      <td>-0.36</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.11</td>\n",
              "      <td>-1.10</td>\n",
              "      <td>0.27</td>\n",
              "      <td>1.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.01</td>\n",
              "      <td>1.01</td>\n",
              "      <td>0.17</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.72</td>\n",
              "      <td>1.42</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.40</td>\n",
              "      <td>1.49</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.72</td>\n",
              "      <td>1.07</td>\n",
              "      <td>2.06</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.02</td>\n",
              "      <td>5.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>-0.19</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.15</td>\n",
              "      <td>-0.47</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.62</td>\n",
              "      <td>1.10</td>\n",
              "      <td>-1.29</td>\n",
              "      <td>0.20</td>\n",
              "      <td>2.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.12</td>\n",
              "      <td>1.13</td>\n",
              "      <td>0.21</td>\n",
              "      <td>-0.29</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.71</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-0.24</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.29</td>\n",
              "      <td>-0.81</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.44</td>\n",
              "      <td>1.38</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.27</td>\n",
              "      <td>-0.54</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.58</td>\n",
              "      <td>1.67</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.30</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.17</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.96</td>\n",
              "      <td>1.91</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.08</td>\n",
              "      <td>3.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>-0.30</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.17</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.04</td>\n",
              "      <td>-1.75</td>\n",
              "      <td>0.08</td>\n",
              "      <td>3.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.01</td>\n",
              "      <td>1.01</td>\n",
              "      <td>0.15</td>\n",
              "      <td>-0.29</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>-0.12</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.20</td>\n",
              "      <td>-0.51</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.29</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.14</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1.53</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.33</td>\n",
              "      <td>1.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.38</td>\n",
              "      <td>1.46</td>\n",
              "      <td>0.20</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.98</td>\n",
              "      <td>2.17</td>\n",
              "      <td>1.86</td>\n",
              "      <td>0.06</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>-0.15</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.63</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.39</td>\n",
              "      <td>-0.60</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.18</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.26</td>\n",
              "      <td>-0.32</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.72</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.49</td>\n",
              "      <td>1.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>-0.19</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.26</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.36</td>\n",
              "      <td>-0.76</td>\n",
              "      <td>0.45</td>\n",
              "      <td>1.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.09</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.15</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.82</td>\n",
              "      <td>1.48</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>-0.23</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.21</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.20</td>\n",
              "      <td>-1.10</td>\n",
              "      <td>0.27</td>\n",
              "      <td>1.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.25</td>\n",
              "      <td>1.28</td>\n",
              "      <td>0.27</td>\n",
              "      <td>-0.28</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.76</td>\n",
              "      <td>2.16</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>1.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>-0.37</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.20</td>\n",
              "      <td>-0.78</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.46</td>\n",
              "      <td>1.03</td>\n",
              "      <td>-1.83</td>\n",
              "      <td>0.07</td>\n",
              "      <td>3.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.52</td>\n",
              "      <td>1.69</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.35</td>\n",
              "      <td>2.12</td>\n",
              "      <td>4.53</td>\n",
              "      <td>&lt;0.005</td>\n",
              "      <td>17.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>-0.50</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.18</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.87</td>\n",
              "      <td>-2.74</td>\n",
              "      <td>0.01</td>\n",
              "      <td>7.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.67</td>\n",
              "      <td>1.96</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.04</td>\n",
              "      <td>1.35</td>\n",
              "      <td>2.83</td>\n",
              "      <td>3.56</td>\n",
              "      <td>&lt;0.005</td>\n",
              "      <td>11.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.12</td>\n",
              "      <td>1.13</td>\n",
              "      <td>0.13</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.88</td>\n",
              "      <td>1.45</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>-0.56</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.20</td>\n",
              "      <td>-0.95</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.84</td>\n",
              "      <td>-2.85</td>\n",
              "      <td>&lt;0.005</td>\n",
              "      <td>7.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.19</td>\n",
              "      <td>1.21</td>\n",
              "      <td>0.18</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.85</td>\n",
              "      <td>1.73</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>-0.12</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.20</td>\n",
              "      <td>-0.52</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.31</td>\n",
              "      <td>-0.62</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.21</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.20</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.83</td>\n",
              "      <td>1.81</td>\n",
              "      <td>1.03</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>-0.26</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.16</td>\n",
              "      <td>-0.58</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.07</td>\n",
              "      <td>-1.57</td>\n",
              "      <td>0.12</td>\n",
              "      <td>3.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.47</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1.08</td>\n",
              "      <td>2.37</td>\n",
              "      <td>2.33</td>\n",
              "      <td>0.02</td>\n",
              "      <td>5.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>-0.29</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.18</td>\n",
              "      <td>-0.65</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>-1.62</td>\n",
              "      <td>0.10</td>\n",
              "      <td>3.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.25</td>\n",
              "      <td>1.29</td>\n",
              "      <td>0.15</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.96</td>\n",
              "      <td>1.72</td>\n",
              "      <td>1.71</td>\n",
              "      <td>0.09</td>\n",
              "      <td>3.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.10</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.18</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.78</td>\n",
              "      <td>1.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.10</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.20</td>\n",
              "      <td>-0.29</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.64</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>-0.50</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.22</td>\n",
              "      <td>-0.93</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.93</td>\n",
              "      <td>-2.31</td>\n",
              "      <td>0.02</td>\n",
              "      <td>5.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.15</td>\n",
              "      <td>1.17</td>\n",
              "      <td>0.13</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.50</td>\n",
              "      <td>1.18</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.07</td>\n",
              "      <td>1.08</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.91</td>\n",
              "      <td>1.27</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.38</td>\n",
              "      <td>1.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.10</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.20</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.59</td>\n",
              "      <td>1.81</td>\n",
              "      <td>1.33</td>\n",
              "      <td>-2.02</td>\n",
              "      <td>3.21</td>\n",
              "      <td>0.13</td>\n",
              "      <td>24.66</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.02</td>\n",
              "      <td>1.02</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.92</td>\n",
              "      <td>1.14</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>-1.68</td>\n",
              "      <td>0.19</td>\n",
              "      <td>2.88</td>\n",
              "      <td>-7.32</td>\n",
              "      <td>3.97</td>\n",
              "      <td>0.00</td>\n",
              "      <td>52.97</td>\n",
              "      <td>-0.58</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.91</td>\n",
              "      <td>1.04</td>\n",
              "      <td>-0.77</td>\n",
              "      <td>0.44</td>\n",
              "      <td>1.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>0.08</td>\n",
              "      <td>1.09</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.16</td>\n",
              "      <td>1.01</td>\n",
              "      <td>1.17</td>\n",
              "      <td>2.14</td>\n",
              "      <td>0.03</td>\n",
              "      <td>4.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>-1.83</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.82</td>\n",
              "      <td>-3.43</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.79</td>\n",
              "      <td>-2.24</td>\n",
              "      <td>0.02</td>\n",
              "      <td>5.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>0.21</td>\n",
              "      <td>1.24</td>\n",
              "      <td>0.11</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.54</td>\n",
              "      <td>1.94</td>\n",
              "      <td>0.05</td>\n",
              "      <td>4.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>-2.13</td>\n",
              "      <td>0.12</td>\n",
              "      <td>1.53</td>\n",
              "      <td>-5.13</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2.36</td>\n",
              "      <td>-1.40</td>\n",
              "      <td>0.16</td>\n",
              "      <td>2.62</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><br><div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Concordance</th>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Partial AIC</th>\n",
              "      <td>464.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>log-likelihood ratio test</th>\n",
              "      <td>106.56 on 55 df</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-log2(p) of ll-ratio test</th>\n",
              "      <td>14.68</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "<lifelines.CoxPHFitter: fitted with 178 total observations, 131 right-censored observations>\n",
              "             duration col = 'Progression free survival'\n",
              "                event col = 'Progression'\n",
              "      baseline estimation = breslow\n",
              "   number of observations = 178\n",
              "number of events observed = 47\n",
              "   partial log-likelihood = -177.42\n",
              "         time fit was run = 2021-09-15 08:38:32 UTC\n",
              "\n",
              "---\n",
              "            coef  exp(coef)   se(coef)   coef lower 95%   coef upper 95%  exp(coef) lower 95%  exp(coef) upper 95%\n",
              "covariate                                                                                                         \n",
              "0           0.02       1.02       0.03            -0.03             0.07                 0.97                 1.08\n",
              "1          -0.94       0.39       1.12            -3.14             1.25                 0.04                 3.49\n",
              "2          -0.60       0.55       0.76            -2.09             0.89                 0.12                 2.44\n",
              "3           1.60       4.94       0.96            -0.29             3.49                 0.75                32.75\n",
              "4           1.04       2.82       0.91            -0.75             2.83                 0.47                16.90\n",
              "5          -0.40       0.67       1.22            -2.78             1.98                 0.06                 7.24\n",
              "6          -2.16       0.12       1.07            -4.25            -0.06                 0.01                 0.94\n",
              "7           1.95       7.01       0.90             0.18             3.72                 1.19                41.16\n",
              "8          -1.09       0.33       0.59            -2.26             0.07                 0.10                 1.07\n",
              "9          -0.13       0.88       0.12            -0.36             0.10                 0.70                 1.11\n",
              "10          0.01       1.01       0.17            -0.33             0.35                 0.72                 1.42\n",
              "11          0.40       1.49       0.17             0.07             0.72                 1.07                 2.06\n",
              "12         -0.19       0.83       0.15            -0.47             0.10                 0.62                 1.10\n",
              "13          0.12       1.13       0.21            -0.29             0.54                 0.75                 1.71\n",
              "14         -0.24       0.78       0.29            -0.81             0.33                 0.44                 1.38\n",
              "15         -0.02       0.98       0.27            -0.54             0.51                 0.58                 1.67\n",
              "16          0.30       1.36       0.17            -0.04             0.64                 0.96                 1.91\n",
              "17         -0.30       0.74       0.17            -0.64             0.04                 0.53                 1.04\n",
              "18          0.01       1.01       0.15            -0.29             0.31                 0.75                 1.36\n",
              "19         -0.12       0.88       0.20            -0.51             0.26                 0.60                 1.29\n",
              "20          0.14       1.15       0.15            -0.15             0.43                 0.86                 1.53\n",
              "21          0.38       1.46       0.20            -0.02             0.78                 0.98                 2.17\n",
              "22         -0.15       0.86       0.25            -0.63             0.33                 0.53                 1.39\n",
              "23          0.18       1.20       0.26            -0.32             0.68                 0.72                 1.98\n",
              "24         -0.19       0.82       0.26            -0.70             0.31                 0.50                 1.36\n",
              "25          0.09       1.10       0.15            -0.20             0.39                 0.82                 1.48\n",
              "26         -0.23       0.80       0.21            -0.64             0.18                 0.53                 1.20\n",
              "27          0.25       1.28       0.27            -0.28             0.77                 0.76                 2.16\n",
              "28         -0.37       0.69       0.20            -0.78             0.03                 0.46                 1.03\n",
              "29          0.52       1.69       0.12             0.30             0.75                 1.35                 2.12\n",
              "30         -0.50       0.61       0.18            -0.85            -0.14                 0.43                 0.87\n",
              "31          0.67       1.96       0.19             0.30             1.04                 1.35                 2.83\n",
              "32          0.12       1.13       0.13            -0.13             0.37                 0.88                 1.45\n",
              "33         -0.56       0.57       0.20            -0.95            -0.18                 0.39                 0.84\n",
              "34          0.19       1.21       0.18            -0.16             0.55                 0.85                 1.73\n",
              "35         -0.12       0.88       0.20            -0.52             0.27                 0.59                 1.31\n",
              "36          0.21       1.23       0.20            -0.18             0.60                 0.83                 1.81\n",
              "37         -0.26       0.77       0.16            -0.58             0.06                 0.56                 1.07\n",
              "38          0.47       1.60       0.20             0.07             0.86                 1.08                 2.37\n",
              "39         -0.29       0.75       0.18            -0.65             0.06                 0.52                 1.06\n",
              "40          0.25       1.29       0.15            -0.04             0.54                 0.96                 1.72\n",
              "41          0.10       1.11       0.18            -0.25             0.45                 0.78                 1.57\n",
              "42          0.10       1.11       0.20            -0.29             0.50                 0.75                 1.64\n",
              "43         -0.50       0.61       0.22            -0.93            -0.08                 0.40                 0.93\n",
              "44          0.15       1.17       0.13            -0.10             0.41                 0.90                 1.50\n",
              "45          0.07       1.08       0.09            -0.09             0.24                 0.91                 1.27\n",
              "46         -0.02       0.98       0.10            -0.22             0.18                 0.80                 1.20\n",
              "47          0.59       1.81       1.33            -2.02             3.21                 0.13                24.66\n",
              "48          0.02       1.02       0.06            -0.09             0.13                 0.92                 1.14\n",
              "49         -1.68       0.19       2.88            -7.32             3.97                 0.00                52.97\n",
              "50         -0.03       0.97       0.04            -0.10             0.04                 0.91                 1.04\n",
              "51          0.08       1.09       0.04             0.01             0.16                 1.01                 1.17\n",
              "53         -1.83       0.16       0.82            -3.43            -0.23                 0.03                 0.79\n",
              "54          0.21       1.24       0.11            -0.00             0.43                 1.00                 1.54\n",
              "56         -2.13       0.12       1.53            -5.13             0.86                 0.01                 2.36\n",
              "\n",
              "              z      p   -log2(p)\n",
              "covariate                        \n",
              "0          0.70   0.49       1.04\n",
              "1         -0.84   0.40       1.33\n",
              "2         -0.79   0.43       1.22\n",
              "3          1.66   0.10       3.36\n",
              "4          1.13   0.26       1.96\n",
              "5         -0.33   0.74       0.43\n",
              "6         -2.02   0.04       4.52\n",
              "7          2.16   0.03       5.01\n",
              "8         -1.84   0.07       3.94\n",
              "9         -1.10   0.27       1.89\n",
              "10         0.04   0.97       0.04\n",
              "11         2.38   0.02       5.85\n",
              "12        -1.29   0.20       2.34\n",
              "13         0.57   0.57       0.82\n",
              "14        -0.84   0.40       1.32\n",
              "15        -0.06   0.95       0.07\n",
              "16         1.75   0.08       3.65\n",
              "17        -1.75   0.08       3.63\n",
              "18         0.08   0.94       0.09\n",
              "19        -0.64   0.52       0.94\n",
              "20         0.97   0.33       1.58\n",
              "21         1.86   0.06       4.00\n",
              "22        -0.60   0.55       0.87\n",
              "23         0.70   0.49       1.04\n",
              "24        -0.76   0.45       1.16\n",
              "25         0.62   0.53       0.91\n",
              "26        -1.10   0.27       1.88\n",
              "27         0.92   0.36       1.48\n",
              "28        -1.83   0.07       3.88\n",
              "29         4.53 <0.005      17.34\n",
              "30        -2.74   0.01       7.33\n",
              "31         3.56 <0.005      11.39\n",
              "32         0.96   0.34       1.58\n",
              "33        -2.85 <0.005       7.84\n",
              "34         1.07   0.29       1.81\n",
              "35        -0.62   0.54       0.89\n",
              "36         1.03   0.30       1.73\n",
              "37        -1.57   0.12       3.10\n",
              "38         2.33   0.02       5.66\n",
              "39        -1.62   0.10       3.26\n",
              "40         1.71   0.09       3.51\n",
              "41         0.57   0.57       0.82\n",
              "42         0.52   0.60       0.73\n",
              "43        -2.31   0.02       5.58\n",
              "44         1.18   0.24       2.08\n",
              "45         0.87   0.38       1.38\n",
              "46        -0.18   0.86       0.22\n",
              "47         0.44   0.66       0.60\n",
              "48         0.42   0.68       0.56\n",
              "49        -0.58   0.56       0.84\n",
              "50        -0.77   0.44       1.18\n",
              "51         2.14   0.03       4.95\n",
              "53        -2.24   0.02       5.33\n",
              "54         1.94   0.05       4.27\n",
              "56        -1.40   0.16       2.62\n",
              "---\n",
              "Concordance = 0.86\n",
              "Partial AIC = 464.85\n",
              "log-likelihood ratio test = 106.56 on 55 df\n",
              "-log2(p) of ll-ratio test = 14.68"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DnYxSARfzOR"
      },
      "source": [
        "Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvgU0uHsf1s8",
        "outputId": "639ba2fe-e5f1-4989-8cd6-d48c91198da4"
      },
      "source": [
        "from lifelines import CoxPHFitter\n",
        "from lifelines.datasets import load_regression_dataset\n",
        "from lifelines.utils import k_fold_cross_validation\n",
        "\n",
        "cph = CoxPHFitter()\n",
        "scores = k_fold_cross_validation(cph, train_df, duration_col = 'Progression free survival', event_col='Progression', scoring_method=\"concordance_index\")\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.8944490880126272, -3.7593693226062217, -10.630003401534584]\n",
            "[0.8014981273408239, 0.4870848708487085, 0.6147540983606558, 0.6100917431192661, 0.47540983606557374]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T-oq-d2zW2v"
      },
      "source": [
        "survival10 = cph10.predict_survival_function(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAftZqcYBqy2"
      },
      "source": [
        "\n",
        "# **DeepHit**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6b3nlNME7Iq"
      },
      "source": [
        "import torch\n",
        "import torchtuples as tt\n",
        "from pycox.evaluation import EvalSurv\n",
        "from pycox.models import DeepHitSingle\n",
        "num_durations = 10 \n",
        "labtrans = DeepHitSingle.label_transform(num_durations)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vYn3FCOdbu0"
      },
      "source": [
        "get_target = lambda df: (df['Progression free survival'].values, df['Progression'].values)\n",
        "y_train = labtrans.fit_transform(*get_target(df_train))\n",
        "y_val = labtrans.transform(*get_target(df_val))\n",
        "\n",
        "train = (x_train, y_train)\n",
        "val = (x_val, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9bIUNpcdqDf"
      },
      "source": [
        "# Model parameters \n",
        "in_features = x_train.shape[1]\n",
        "num_nodes = [32, 32]\n",
        "out_features = labtrans.out_features\n",
        "print(out_features)\n",
        "batch_norm = True\n",
        "dropout = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejr--JV5bCQ-"
      },
      "source": [
        " import torch\n",
        " net = torch.nn.Sequential(\n",
        "     torch.nn.Linear(in_features, 32),\n",
        "     torch.nn.ReLU(),\n",
        "     torch.nn.BatchNorm1d(32),\n",
        "     torch.nn.Dropout(0.2),\n",
        "    \n",
        "     torch.nn.Linear(32, 32),\n",
        "     torch.nn.ReLU(),\n",
        "     torch.nn.BatchNorm1d(32),\n",
        "     torch.nn.Dropout(0.5),\n",
        "    \n",
        "     torch.nn.Linear(32, out_features)\n",
        " )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLzxRjHgE3re"
      },
      "source": [
        "model = DeepHitSingle(net, tt.optim.Adam, alpha=0.2, sigma=0.1, duration_index=labtrans.cuts)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ihtOxxHfE6Mu",
        "outputId": "48df35fd-6c5a-4f14-d72f-2371a6ab1973"
      },
      "source": [
        "batch_size = 50\n",
        "lr_finder = model.lr_finder(x_train, y_train, batch_size, tolerance=3)\n",
        "_ = lr_finder.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mlu6BM7xdw9I",
        "outputId": "d1f33d69-f246-4515-da8b-36824a8f9e28"
      },
      "source": [
        "lr_finder.get_best_lr()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001"
            ]
          },
          "metadata": {},
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLsbrHtNdzvk"
      },
      "source": [
        "model.optimizer.set_lr(0.0001)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djxA_8Vfd3ra",
        "outputId": "e8785e60-afa9-421d-8630-e419bb3bb65a"
      },
      "source": [
        "epochs = 100\n",
        "callbacks = [tt.callbacks.EarlyStopping()]\n",
        "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, val_data=val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 1.1382,\tval_loss: 0.3568\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 0.5577,\tval_loss: 0.3559\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 0.8945,\tval_loss: 0.3553\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 0.9652,\tval_loss: 0.3549\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 1.3153,\tval_loss: 0.3549\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 0.7897,\tval_loss: 0.3548\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 0.7750,\tval_loss: 0.3546\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 0.6511,\tval_loss: 0.3552\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 0.8995,\tval_loss: 0.3555\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 0.8993,\tval_loss: 0.3564\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 1.0945,\tval_loss: 0.3569\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 0.8863,\tval_loss: 0.3564\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 1.7303,\tval_loss: 0.3574\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 0.5061,\tval_loss: 0.3576\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 0.9115,\tval_loss: 0.3573\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 0.8989,\tval_loss: 0.3574\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 0.5756,\tval_loss: 0.3583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "2WtIzPJad7V5",
        "outputId": "b13c93aa-63fa-4d01-c7f4-fee89bcd0d2e"
      },
      "source": [
        "_ = log.plot()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EkeNim4d_UJ"
      },
      "source": [
        "Prediction DeepHit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyW4UWV1eBuL"
      },
      "source": [
        "surv = model.predict_surv_df(x_val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "u-BEaI_UeJca",
        "outputId": "d2862966-11e0-415b-94f0-34d4f881a52b"
      },
      "source": [
        "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
        "plt.ylabel('S(t | x)')\n",
        "_ = plt.xlabel('Time')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M0AZ0AFeNCA"
      },
      "source": [
        "surv = model.interpolate(10).predict_surv_df(x_val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "WMJP1wNhePsX",
        "outputId": "809e93e4-f4ab-48d4-d676-ac063fee29c4"
      },
      "source": [
        "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
        "plt.ylabel('S(t | x)')\n",
        "_ = plt.xlabel('Time')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUuh-JcAeUyo"
      },
      "source": [
        "ev = EvalSurv(surv, times_val, events_val, censor_surv='km')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "Zyv0zHo0lTNJ",
        "outputId": "d13785e8-5d69-4d65-b2cb-2a170260f5d6"
      },
      "source": [
        "time_grid = np.linspace(times_val.min(), times_val.max(), 100)\n",
        "ev.brier_score(time_grid).plot()\n",
        "plt.ylabel('Brier score')\n",
        "_ = plt.xlabel('Time')\n",
        "print(\"Brier score:\",ev.integrated_nbll(time_grid))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brier score: 0.5102989706945327\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoNogdcldObl",
        "outputId": "5aca1497-8244-46bf-9275-ec81abbf6c7b"
      },
      "source": [
        "# C-index \n",
        "from lifelines.utils import concordance_index\n",
        "concordance_index(times_val, predictions, events_val)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6684491978609626"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvOn40OTVOiY"
      },
      "source": [
        "# **DeepSurv**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYMTe5MBVUdY"
      },
      "source": [
        "import torch.nn as nn\n",
        "class CoxNet(nn.Module):\n",
        "  \"\"\"CoxPH like model\"\"\"\n",
        "  def __init__(self, H1 = 32, H2 = 32):\n",
        "    super(CoxNet, self).__init__()\n",
        "    self.net = torch.nn.Sequential(nn.Linear(47, H1),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.BatchNorm1d(H1),\n",
        "                                   nn.Dropout(0.3),\n",
        "                                   nn.Linear(H1, H2),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.BatchNorm1d(H2),\n",
        "                                   nn.Dropout(0.1),\n",
        "                                   nn.Linear(H2, 1))\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.net(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ56U9nGVYo7"
      },
      "source": [
        "net = CoxNet()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "#optimizer = tt.optim.SGD(lr=1e-3, momentum=0.9, weight_decay=3e-4, nesterov=True)\n",
        "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,cycle_multiplier=2)\n",
        "model = CoxPH(net, optimizer = optimizer, device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYxE-qkYVamG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "aaa9cfa7-6277-49d4-b8ef-cc022a690831"
      },
      "source": [
        "batch_size = 50 \n",
        "lrfinder = model.lr_finder(x_train, y_train, batch_size, tolerance=10)\n",
        "# Learning rate finder often overestimate the learning rate so choose a lower value\n",
        "lrfinder.plot()\n",
        "plt.show()\n",
        "print(lrfinder.get_best_lr())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01149756995397742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "MBMH7mamVd85",
        "outputId": "06e2e7ff-3f90-434e-c3ea-bf83889e77c8"
      },
      "source": [
        "model.optimizer.set_lr(0.01)\n",
        "batch_size = 50\n",
        "epochs = 100\n",
        "callbacks = [tt.callbacks.EarlyStopping()]\n",
        "verbose = True\n",
        "\n",
        "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose, val_data=(x_val,y_val), val_batch_size=batch_size)\n",
        "log.plot()\n",
        "plt.show()\n",
        "print(model.partial_log_likelihood(*(x_val,y_val)).mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[0s / 0s],\t\ttrain_loss: 3.6819,\tval_loss: 3.6279\n",
            "1:\t[0s / 0s],\t\ttrain_loss: 3.3424,\tval_loss: 3.6113\n",
            "2:\t[0s / 0s],\t\ttrain_loss: 3.3906,\tval_loss: 3.6080\n",
            "3:\t[0s / 0s],\t\ttrain_loss: 3.4498,\tval_loss: 3.5880\n",
            "4:\t[0s / 0s],\t\ttrain_loss: 3.3896,\tval_loss: 3.5645\n",
            "5:\t[0s / 0s],\t\ttrain_loss: 3.3455,\tval_loss: 3.5629\n",
            "6:\t[0s / 0s],\t\ttrain_loss: 3.4997,\tval_loss: 3.5572\n",
            "7:\t[0s / 0s],\t\ttrain_loss: 3.2316,\tval_loss: 3.5878\n",
            "8:\t[0s / 0s],\t\ttrain_loss: 3.2359,\tval_loss: 3.6021\n",
            "9:\t[0s / 0s],\t\ttrain_loss: 3.2756,\tval_loss: 3.5791\n",
            "10:\t[0s / 0s],\t\ttrain_loss: 3.2408,\tval_loss: 3.5286\n",
            "11:\t[0s / 0s],\t\ttrain_loss: 3.1728,\tval_loss: 3.5478\n",
            "12:\t[0s / 0s],\t\ttrain_loss: 3.2063,\tval_loss: 3.5459\n",
            "13:\t[0s / 0s],\t\ttrain_loss: 3.2347,\tval_loss: 3.5374\n",
            "14:\t[0s / 0s],\t\ttrain_loss: 3.0463,\tval_loss: 3.5398\n",
            "15:\t[0s / 0s],\t\ttrain_loss: 3.2214,\tval_loss: 3.4810\n",
            "16:\t[0s / 0s],\t\ttrain_loss: 3.0633,\tval_loss: 3.4976\n",
            "17:\t[0s / 0s],\t\ttrain_loss: 3.0516,\tval_loss: 3.5061\n",
            "18:\t[0s / 0s],\t\ttrain_loss: 3.1059,\tval_loss: 3.4980\n",
            "19:\t[0s / 0s],\t\ttrain_loss: 3.0375,\tval_loss: 3.5414\n",
            "20:\t[0s / 0s],\t\ttrain_loss: 3.0738,\tval_loss: 3.5877\n",
            "21:\t[0s / 0s],\t\ttrain_loss: 3.0039,\tval_loss: 3.5278\n",
            "22:\t[0s / 0s],\t\ttrain_loss: 2.8515,\tval_loss: 3.5477\n",
            "23:\t[0s / 0s],\t\ttrain_loss: 3.1443,\tval_loss: 3.5536\n",
            "24:\t[0s / 0s],\t\ttrain_loss: 3.0276,\tval_loss: 3.5786\n",
            "25:\t[0s / 0s],\t\ttrain_loss: 2.9859,\tval_loss: 3.6047\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-3.481001377105713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "A0eSAYwfVgWz",
        "outputId": "53ef77c2-095e-4401-8b16-7461e0930a07"
      },
      "source": [
        "# Predicted survival curve on validation set for 5 patients\n",
        "_ = model.compute_baseline_hazards()\n",
        "surv = model.predict_surv_df(x_test)\n",
        "surv.iloc[:,:5].plot()\n",
        "plt.ylabel('S(t | x)')\n",
        "_ = plt.xlabel('Time')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pycox/models/cox.py:257: RuntimeWarning: overflow encountered in exp\n",
            "  expg = np.exp(self.predict(input, batch_size, True, eval_, num_workers=num_workers)).reshape(1, -1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "H-15wGS1ViYn",
        "outputId": "b3d5b484-00ce-439d-f72e-8834b9eb8aaa"
      },
      "source": [
        "# Predicted survival metrics ie. Concordance index and Brier score on validation set\n",
        "dur = times_val\n",
        "eve = events_val\n",
        "ev = EvalSurv(surv, dur, eve, censor_surv='km')\n",
        "print(ev.concordance_td())\n",
        "time_grid = np.linspace(dur.min(), dur.max(), 100)\n",
        "_ = ev.brier_score(time_grid).plot()\n",
        "print(ev.integrated_nbll(time_grid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7085561497326203\n",
            "0.5085983168948585\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4E1w69NdFO0"
      },
      "source": [
        "## **3.Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98q8sl3A5RLk"
      },
      "source": [
        "\n",
        "def Concordance_index(event_times, predicted_scores, event_observed=None):\n",
        "    \"\"\"\n",
        "    Code adapted from https://github.com/CamDavidsonPilon/lifelines/blob/master/lifelines/utils/concordance.py\n",
        "    to account for missing values in the context of the HECKTOR Challenge\n",
        "    Missing values are encoded by NaNs and are computed as non-concordant.\n",
        "    \"\"\"\n",
        "    event_times, predicted_scores, event_observed = _preprocess_scoring_data(\n",
        "        event_times, predicted_scores, event_observed)\n",
        "    # num_correct, num_tied, num_pairs = _concordance_summary_statistics(\n",
        "    #     event_times, predicted_scores, event_observed)\n",
        "    num_correct, num_tied, num_pairs = _naive_concordance_summary_statistics(\n",
        "        event_times, predicted_scores, event_observed)\n",
        "\n",
        "    return _concordance_ratio(num_correct, num_tied, num_pairs)\n",
        "\n",
        "\n",
        "def _concordance_ratio(num_correct, num_tied, num_pairs):\n",
        "    \"\"\"\n",
        "    Code adapted from https://github.com/CamDavidsonPilon/lifelines/blob/master/lifelines/utils/concordance.py\n",
        "    to account for missing values in the context of the HECKTOR Challenge\n",
        "    \"\"\"\n",
        "    if num_pairs == 0:\n",
        "        raise ZeroDivisionError(\"No admissable pairs in the dataset.\")\n",
        "    return (num_correct + num_tied / 2) / num_pairs\n",
        "\n",
        "\n",
        "def _naive_concordance_summary_statistics(event_times, predicted_event_times,\n",
        "                                          event_observed):\n",
        "    \"\"\"\n",
        "    Code adapted from https://github.com/CamDavidsonPilon/lifelines/blob/master/lifelines/utils/concordance.py\n",
        "    to account for missing values in the context of the HECKTOR Challenge\n",
        "    \"\"\"\n",
        "    def _valid_comparison(time_a, time_b, event_a, event_b):\n",
        "        \"\"\"True if times can be compared.\"\"\"\n",
        "        if time_a == time_b:\n",
        "            # Ties are only informative if exactly one event happened\n",
        "            return event_a != event_b\n",
        "        if event_a and event_b:\n",
        "            return True\n",
        "        if event_a and time_a < time_b:\n",
        "            return True\n",
        "        if event_b and time_b < time_a:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def _concordance_value(time_a, time_b, pred_a, pred_b, event_a, event_b):\n",
        "        if np.isnan(pred_a) or np.isnan(pred_b):\n",
        "            # Missing values, same as random\n",
        "            return (0, 1)\n",
        "        if pred_a == pred_b:\n",
        "            # Same as random\n",
        "            return (0, 1)\n",
        "        if pred_a < pred_b:\n",
        "            return (time_a < time_b) or (time_a == time_b and event_a\n",
        "                                         and not event_b), 0\n",
        "        # pred_a > pred_b\n",
        "        return (time_a > time_b) or (time_a == time_b and not event_a\n",
        "                                     and event_b), 0\n",
        "\n",
        "    num_pairs = 0.0\n",
        "    num_correct = 0.0\n",
        "    num_tied = 0.0\n",
        "\n",
        "    for a, time_a in enumerate(event_times):\n",
        "        pred_a = predicted_event_times[a]\n",
        "        event_a = event_observed[a]\n",
        "        # Don't want to double count\n",
        "        for b in range(a + 1, len(event_times)):\n",
        "            time_b = event_times[b]\n",
        "            pred_b = predicted_event_times[b]\n",
        "            event_b = event_observed[b]\n",
        "\n",
        "            if _valid_comparison(time_a, time_b, event_a, event_b):\n",
        "                num_pairs += 1.0\n",
        "                crct, ties = _concordance_value(time_a, time_b, pred_a, pred_b,\n",
        "                                                event_a, event_b)\n",
        "                num_correct += crct\n",
        "                num_tied += ties\n",
        "\n",
        "    return (num_correct, num_tied, num_pairs)\n",
        "\n",
        "\n",
        "def _preprocess_scoring_data(event_times, predicted_scores, event_observed):\n",
        "    \"\"\"\n",
        "    Code adapted from https://github.com/CamDavidsonPilon/lifelines/blob/master/lifelines/utils/concordance.py\n",
        "    to account for missing values in the context of the HECKTOR Challenge\n",
        "    \"\"\"\n",
        "    event_times = np.asarray(event_times, dtype=float)\n",
        "    predicted_scores = np.asarray(predicted_scores, dtype=float)\n",
        "\n",
        "    # Allow for (n, 1) or (1, n) arrays\n",
        "    if event_times.ndim == 2 and (event_times.shape[0] == 1\n",
        "                                  or event_times.shape[1] == 1):\n",
        "        # Flatten array\n",
        "        event_times = event_times.ravel()\n",
        "    # Allow for (n, 1) or (1, n) arrays\n",
        "    if predicted_scores.ndim == 2 and (predicted_scores.shape[0] == 1\n",
        "                                       or predicted_scores.shape[1] == 1):\n",
        "        # Flatten array\n",
        "        predicted_scores = predicted_scores.ravel()\n",
        "\n",
        "    if event_times.shape != predicted_scores.shape:\n",
        "        raise ValueError(\n",
        "            \"Event times and predictions must have the same shape\")\n",
        "    if event_times.ndim != 1:\n",
        "        raise ValueError(\"Event times can only be 1-dimensional: (n,)\")\n",
        "\n",
        "    if event_observed is None:\n",
        "        event_observed = np.ones(event_times.shape[0], dtype=float)\n",
        "    else:\n",
        "        event_observed = np.asarray(event_observed, dtype=float).ravel()\n",
        "        if event_observed.shape != event_times.shape:\n",
        "            raise ValueError(\n",
        "                \"Observed events must be 1-dimensional of same length as event times\"\n",
        "            )\n",
        "    # Commented out since we rely on NaNs to count missing patients\n",
        "    # check for NaNs\n",
        "    # for a in [event_times, predicted_scores, event_observed]:\n",
        "    #     if np.isnan(a).any():\n",
        "    #         raise ValueError(\n",
        "    #             \"NaNs detected in inputs, please correct or drop.\")\n",
        "\n",
        "    return event_times, predicted_scores, event_observed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXszmVI57e21",
        "outputId": "f20e8587-d31d-4f16-87dc-1119df30ffb0"
      },
      "source": [
        "Concordance_index(times_val,  predictions, event_observed=events_val) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8101604278074866"
            ]
          },
          "metadata": {},
          "execution_count": 348
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4FuZuUcj4co"
      },
      "source": [
        "def predict(prediction, threshold=0.9):\n",
        "    surv_predictions = []\n",
        "    for _, pred in prediction.iteritems():\n",
        "        times = pred.index.values\n",
        "        for time in times:\n",
        "          if pred[time] <= threshold:\n",
        "            t = time\n",
        "            break\n",
        "        else:\n",
        "          t = times[-1]\n",
        "        surv_predictions.append(t)\n",
        "    return pd.DataFrame(np.array([surv for surv in surv_predictions]), columns=['Progression free survival'])\n",
        "\n",
        "# CoxPH Survival Model Ensembling (average) on different train-val splits:\n",
        "models = []\n",
        "models = [survival + str(i) for i in range(10)]\n",
        "pred = []\n",
        "pred = [predict(model, 0.9) for model in models]\n",
        "predictions = np.mean(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t-Trmqu4k0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa3c1e3-8caf-46ef-c5f4-b706386687e2"
      },
      "source": [
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      241.0\n",
            "1     3067.0\n",
            "2      781.0\n",
            "3     3067.0\n",
            "4     1029.0\n",
            "5     1091.0\n",
            "6     1411.0\n",
            "7      146.0\n",
            "8     3067.0\n",
            "9      499.0\n",
            "10     707.0\n",
            "11     295.0\n",
            "12     499.0\n",
            "13    3067.0\n",
            "14    1106.0\n",
            "15    3067.0\n",
            "16    1910.0\n",
            "17     489.0\n",
            "18    3067.0\n",
            "19    3067.0\n",
            "20     935.0\n",
            "21    1690.0\n",
            "22     705.0\n",
            "23    3067.0\n",
            "24    1411.0\n",
            "25    1690.0\n",
            "26    3067.0\n",
            "27     768.0\n",
            "28    3067.0\n",
            "29     771.0\n",
            "30     322.0\n",
            "31     705.0\n",
            "32     489.0\n",
            "33     828.0\n",
            "34    1194.0\n",
            "35     707.0\n",
            "36     768.0\n",
            "37     272.0\n",
            "38     771.0\n",
            "39     322.0\n",
            "40    1106.0\n",
            "41     828.0\n",
            "42    1910.0\n",
            "43    3067.0\n",
            "44     502.0\n",
            "Name: Progression free survival, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24N6MWc9DFyi"
      },
      "source": [
        "# **4.Submission**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ04cHe-DDqq"
      },
      "source": [
        "# Generate Submission File \n",
        "Submission = pd.DataFrame({'PatientID': TEST['PatientID'],'Progression Free Survival': -predictions}) \n",
        "Submission.to_csv(\"Submission.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}